@inproceedings{10.1145/3756580.3756665,
author = {Zhang, Yadong and Zheng, Yujuan and Yin, Chen and Wang, Wei},
title = {Research and System Design of Digital Education Mechanism for Vocational Education in Cloud Computing Environment},
year = {2025},
isbn = {9798400715624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756580.3756665},
doi = {10.1145/3756580.3756665},
abstract = {This study aims to address the core issues of vocational education in the current cloud computing environment, such as the curriculum system lagging behind technological development and the lack of dynamic data support for talent skill assessment. It aims to build a digital education mechanism and system platform based on cloud computing and artificial intelligence technology, and achieve accurate matching of vocational education with industry needs by establishing an education model of "data-driven-intelligent adaptation-dynamic feedback". First, crawler technology is used to integrate 46,000 cloud computing job recruitment data and 32 vocational college teaching data to construct a job capability knowledge graph; secondly, learner portraits are classified based on the K-means clustering algorithm, and a dynamic evaluation system containing 8 dimensions and 64 indicators is established; then a system architecture with three core functions of intelligent course recommendation, virtual training environment, and real-time capability assessment is designed, and an LSTM neural network is introduced for learning behavior prediction. Within a 12-month period of three pilot colleges, the system enables learners to achieve a job adaptation rate of 85.2%, a mean resource allocation delay of 9.24ms, and an employment rate of 92.5%, which verifies the remarkable effect of this mechanism in improving the adaptability of vocational education and provides a replicable technical path for vocational education reform under the background of digital transformation.},
booktitle = {Proceedings of the 2025 6th International Conference on Education, Knowledge and Information Management},
pages = {519–524},
numpages = {6},
keywords = {Cloud Computing Environment, Digitalization of Vocational Education, Research on Education Mechanism, TF-IDF, Word2Vec},
location = {
},
series = {ICEKIM '25}
}

@inproceedings{10.1145/3323933.3324089,
author = {G\"{u}rsel, Emiro\u{g}lu B\"{u}lent and Tarek, Alshiply},
title = {Analysis Of Interoperability In Cloud Computing},
year = {2019},
isbn = {9781450371810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3323933.3324089},
doi = {10.1145/3323933.3324089},
abstract = {Today most of traditional forms of education are not suitable for requirements of educational development and can't keep up with changes in learning demand over time, but Computer networks have provided many opportunities for it. By Cloud Computing software and files are imported into cloud, so word processing, presentations, databases, and more can be accessed from a web browsers. Educational institutions can take advantage of cloud applications to provide students and teachers with free or cost-effective alternatives instead of expensive proprietary productivity tools. In this paper we use semantic models in cloud computing to provide platform-independent data presentation and improve the description of the service. We analyze and discuss how cloud computing can affect boundaries of educational resources in background of semantic web by providing a technological solution using experimental and semantic platforms and numerically cloud services.},
booktitle = {Proceedings of the 2019 5th International Conference on Computer and Technology Applications},
pages = {189–192},
numpages = {4},
keywords = {Cloud Computing, Limit of System Resources, Semantic Techniques},
location = {Istanbul, Turkey},
series = {ICCTA '19}
}

@article{10.14778/3685800.3685810,
author = {Yi, Peng and Liang, Lei and Zhang, Da and Chen, Yong and Zhu, Jinye and Liu, Xiangyu and Tang, Kun and Chen, Jialin and Lin, Hao and Qiu, Leijie and Zhou, Jun},
title = {KGFabric: A Scalable Knowledge Graph Warehouse for Enterprise Data Interconnection},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685810},
doi = {10.14778/3685800.3685810},
abstract = {Based on the diversified application scenarios at Ant Group, we built the Ant Knowledge Graph Platform (AKGP). It has constructed numerous domain-specific knowledge graphs related to merchants, companies, accounts, products, and more. AKGP manages trillions of structured knowledge graphs, serving search, recommendation, risk control and other businesses. However, as the demand increasing for various workloads such as graph pattern matching, graph representation learning, and cross-domain knowledge reuse, the existing warehouse systems based on relational DBMS or graph databases are unable to meet the requirements. To address these issues, we propose KGFabric, an industrial-scale knowledge graph management system built on the distributed file system (DFS). KGFabric offers a nearline knowledge storage engine that utilizes a Semantic-enhanced Programmable Graph (SPG) model, which is compatible with the Labeled Property Graph (LPG) model. The data is persistently stored in DFS, such as HDFS, which leverages the POSIX file system API, making it suitable for deployment in multi-cloud environment at low cost. KGFabric provides a native graph-based and hybrid storage format that can serve as a shared backend for parallel graph computing systems, significantly accelerating the analysis of multi-workload. Additionally, KGFabric includes a graph fabric framework that minimizes data duplication and guarantees data security.KGFabric is able to manage Peta-scale data and has supported graph fabric and analysis with over 100 billion relations at Ant Group. We conduct experiments on various datasets to evaluate the performance of KGFabric. Compared with popular relational DBMS and graph databases, the storage space for semantic relations is reduced by over 90%. The performance of graph fabric improves by 21\texttimes{} in real-world workloads. In multi-hop semantic graph analysis, KGFabric enhances performance by 100\texttimes{}.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3841–3854},
numpages = {14}
}

@inproceedings{10.1145/3078714.3078751,
author = {Mika, Peter},
title = {What Happened To The Semantic Web?},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078751},
doi = {10.1145/3078714.3078751},
abstract = {The idea of the Semantic Web has surfaced in the literature over 20 years ago, and this area has been a major focus of academic research and standardisation for almost as long. In this talk, we look back at the history of the Semantic Web. We discuss what the original aspirations of its creators were, and what has been achieved in practice in these two decades. We also seek to find where the Semantic Web has failed and succeeded, illustrated by usage in web search, e-commerce and online media. Further, we will attempt to understand whether it makes sense to pursue at least some of these ideas in a different age, with new opportunities brought about by recent developments in Big Data, cloud computing, and Deep Learning.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {3},
numpages = {1},
keywords = {linked data, ontology, semantic web},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/2928294.2928304,
author = {De Witte, Dieter and De Vocht, Laurens and Verborgh, Ruben and Knecht, Kenny and Pattyn, Filip and Constandt, Hans and Mannens, Erik and Van de Walle, Rik},
title = {Big linked data ETL benchmark on cloud commodity hardware},
year = {2016},
isbn = {9781450342995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2928294.2928304},
doi = {10.1145/2928294.2928304},
abstract = {Linked Data storage solutions often optimize for low latency querying and quick responsiveness. Meanwhile, in the back-end, offline ETL processes take care of integrating and preparing the data. In this paper we explain a workflow and the results of a benchmark that examines which Linked Data storage solution and setup should be chosen for different dataset sizes to optimize the cost-effectiveness of the entire ETL process. The benchmark executes diversified stress tests on the storage solutions. The results include an in-depth analysis of four mature Linked Data solutions with commercial support and full SPARQL 1.1 compliance. Whereas traditional benchmarks studies generally deploy the triple stores on premises using high-end hardware, this benchmark uses publicly available cloud machine images for reproducibility and runs on commodity hardware. All stores are tested using their default configuration. In this setting Virtuoso shows the best performance in general. The other tree stores show competitive results and have disjunct areas of excellence. Finally, it is shown that each store's performance heavily depends on the structural properties of the queries, giving an indication of where vendors can focus their optimization efforts.},
booktitle = {Proceedings of the International Workshop on Semantic Big Data},
articleno = {12},
numpages = {6},
keywords = {SPARQL, benchmark, big data, cloud computing, linked data},
location = {San Francisco, California},
series = {SBD '16}
}

@inproceedings{10.1145/3308560.3317711,
author = {Shinavier, Joshua and Branson, Kim and Zhang, Wei and Dastgheib, Shima and Gao, Yuqing and Arsintescu, Bogdan and \"{O}zcan, Fatma and Meij, Edgar},
title = {Panel: Knowledge Graph Industry Applications},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317711},
doi = {10.1145/3308560.3317711},
abstract = {This panel will focus on industry applications related to knowledge graph and showcase how knowledge graph transforms the conventional and unconventional industries to the new era of AI, ranging from innovations in medicine and healthcare, literature search, e-commerce, professional connections, to getting a ride.Panelists are: Senior Software Engineer/Research Scientist at Uber, Co-founder of Tinkerpop, specialized on real-time semantics, RDF streams and graph databases Head of AI at Genentech, passionate about modeling, and currently developing a general medical inference engine that can be applied to a wide variety of areas, from point of care decision support, triage, insurance risk managment to name a few A senior staff engineer/director at Business Platform Unit, Alibaba, leading product knowledge graph (PKG) team and Business Platform AI team. He and his team have built a huge PKG with 10 billion of entities. Data Scientist at Numedii, previously postdoctoral research fellow at Stanford University School of Medicine, developing novel methods to integrate and explore a broad set of biological and clinical data for scientific reproducibility and biomedical discovery. An accomplished technical scientist, innovator and R&amp;D leader in cutting-edge technology research and product development. Proven track record of success (20+ years of successful professional career in leading R&amp;D organizations) in leading rapid technological advancement, innovation, and highly competitive environments. Broad range of skills from initiating research breakthroughs to achieving marketable product development. Renowned expert and technological visionary in the fields of enterprise middleware, cloud computing, data centric computing, workload optimized systems and appliances, business analytics, big data, social media and multimedia, speech and natural language processing. Extended technical leadership in systems design for LinkedIn Economic Graph, Google Search and Google Research. Breadth and depth of expertise in building data systems and platforms. Technical leadership and management of software development in both start-up and large companies. A principal research staff member, and a senior manager at IBM Almaden Research Center. I manage the information management department, working on HTAP (hybrid transactional and analytical processing) systems, large scale machine learning, and natural language querying of data. A team lead and senior scientist at Bloomberg. He holds a PhD in computer science from the University of Amsterdam and has an extensive track record in artificial intelligence, information retrieval, knowledge graphs, natural language processing, and machine learning. Before joining Bloomberg he worked at Yahoo Labs on semantic search at web scale using the Yahoo Knowledge Graph. At Bloomberg he leads the team that is responsible for leveraging knowledge graph technology to drive advanced financial insights.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {676},
numpages = {1},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3066911.3066916,
author = {Krzyzanowski, M. C. and Levy, J. and Page, G. P. and Gaddis, N. C. and Clark, R. F.},
title = {Using semantic web technologies to power LungMAP, a molecular data repository},
year = {2017},
isbn = {9781450349871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3066911.3066916},
doi = {10.1145/3066911.3066916},
abstract = {As scientific research evolves, data continue to grow at an exponential rate. This growth calls for a need for more data repositories to store the data, and the creation of additional centralized repositories to provide standards for researchers. Common data repositories allow for collaboration and easier sharing of data, critical for further advancement of scientific understanding of a variety of topics. LungMAP (the Molecular Atlas of Lung Development) is an open-access reference resource that provides a comprehensive molecular atlas of the normal developing lung in humans and mice and provides data and reagents to the research community. The database utilizes RDF, SPARQL, and OWL. LungMAP exemplifies the use of semantic web technologies to provide a collaborative and open access data application for the scientific research community.},
booktitle = {Proceedings of The International Workshop on Semantic Big Data},
articleno = {8},
numpages = {6},
keywords = {OWL, OpenLayers, RDF, cloud computing, ontology, semantics},
location = {Chicago, Illinois},
series = {SBD '17}
}

@inproceedings{10.1145/3093742.3095094,
author = {Dayarathna, Miyuru and Akmeemana, Prabhash and Perera, Srinath and Jayasinghe, Malith},
title = {Solution Recommender for System Failure Recovery via Log Event Pattern Matching on a Knowledge Graph: Demo},
year = {2017},
isbn = {9781450350655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093742.3095094},
doi = {10.1145/3093742.3095094},
abstract = {System anomalies such as network interruptions, operating system halt, disk crash could result in significant financial losses to organizations. In this demonstration we describe a novel log event analysis framework called Solution Recommender which provides a ranked list of solutions to overcome such system errors. The solution recommender gathers log events via a publisher/subscriber mechanism and indexes them inside the WSO2 Data Analytics Server (DAS). Collected information is analyzed using a knowledge graph which conducts log event pattern matching to identify solutions for system failures. We have implemented the proposed approach on WSO2 Log Analyzer for WSO2 API Manager and tested its functionality. In this paper we describe our experience of implementing the log event recommender interlace, the first such recommender developed in a log event analyzer system. The insights presented here will assist practitioners with implementing such Log Event analysis solutions for real world scenarios.},
booktitle = {Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems},
pages = {331–334},
numpages = {4},
keywords = {Application Debugging, Cloud computing, Data Visualization, Event Pattern Matching, Events, Log Analysis, Systems Administration},
location = {Barcelona, Spain},
series = {DEBS '17}
}

@inproceedings{10.1145/3727505.3727537,
author = {Qiu, Ziliang and Deng, Wei and Huang, Juzheng and Liu, Xuezhi and Ren, Binhua and Qin, Siyuan},
title = {Cloud platform resource capacity management and scheduling optimization based on data graph},
year = {2025},
isbn = {9798400713620},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727505.3727537},
doi = {10.1145/3727505.3727537},
abstract = {This paper proposes a data graph based cloud platform resource capacity management and scheduling optimization method to address the difficulty of handling large-scale multi-dimensional constraints in cloud platform resource scheduling. We constructs a multi-level resource graph model for cloud platforms, which realizes the formal description of resource entities, attributes and relationships. Based on this, we designe a resource capacity prediction method that integrates graph neural networks, which improves prediction accuracy by modeling node feature sequences. Meanwhile, we propose an improved multi-objective optimization algorithm that maximizes resource utilization, minimizes system energy consumption, and balances load as optimization objectives, ultimately achieving adaptive optimization of scheduling schemes. The experimental results show that compared with traditional methods, the proposed method improves resource utilization by 24%, reduces average response time by 52.8%, and achieves an SLA satisfaction rate of 98%. Further, in large-scale scenarios (1000+containers), the algorithm can converge to a stable solution within 9 iterations. When the cluster size expanded from 10 nodes to 50 nodes, the scheduling decision time only increased by 42%, verifying the good scalability of this method. The research results have important theoretical and practical value for improving the efficiency of cloud platform resource management.},
booktitle = {Proceedings of the 2025 International Conference on Big Data, Communication Technology and Computer Applications},
pages = {189–192},
numpages = {4},
keywords = {Cloud Computing, Knowledge Graph, Multi-objective Optimization, Resource Scheduling},
location = {
},
series = {BDCTA '25}
}

@inproceedings{10.1145/3687311.3687317,
author = {Ji, Zibo and Li, Yanjun and Yang, Ruiting and Wu, Haoning},
title = {Research on the application and practice of curriculum with AI assistance based on students' adaptive learning needs},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687317},
doi = {10.1145/3687311.3687317},
abstract = {In the era of continuous development of education from informationization to digital transformation, in order to improve students' learning autonomy in mechanics courses and to solve the problem of resource richness and personalized demand of mechanics course teaching under the demand of students' self-adaptive learning, through the fusion technology of big language model and knowledge graph, the interaction technology of Solidworks 3D modeling and Realibox rendering, and cloud computing, cloud supervision and other technological tools to assist teaching by providing knowledge systematic model and visualization model to help students effectively complete the learning tasks and cultivate and improve their independent learning ability. Supervision and other technical tools through the provision of knowledge systematic model and visualization model to assist teaching, help students effectively complete the learning task and cultivate and improve independent learning ability.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {30–34},
numpages = {5},
location = {Guilin, China},
series = {IECT '24}
}

@inproceedings{10.1145/3286606.3286859,
author = {Kaoutar, Lamrani and Abderrahim, Ghadi and Kudagba, Florent Kunal\`{e}},
title = {Semantic Querying Big and Distributed RDF Data},
year = {2018},
isbn = {9781450365628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286606.3286859},
doi = {10.1145/3286606.3286859},
abstract = {Today, the Web knows a rapid increase in data level that makes their processing and storage limited in traditional technologies. That is why future technology tries to exploit the notion of semantics and ontology by adapting them to big data technology to allow a fundamental change in the access to voluminous information in the web. That Intended to have a complete and relevant response to the user request.Our research work focuses on the semantic web. Focus exactly on the semantic search on many data expressed by RDF (Resource Description Framework) in distributed system. The semantic language proposed by W3C (World Wide Web Consortium) provides the formalism necessary for the representation of data for the Semantic Web. However, only a knowledge representation format is insufficient and we need powerful response mechanisms to manage effectively global and distributed queries across a set of stand-alone and heterogeneous RDF resources marked by the dynamic and scalable nature of their content.},
booktitle = {Proceedings of the 3rd International Conference on Smart City Applications},
articleno = {82},
numpages = {5},
keywords = {Cloud computing, Semantic web, big data, distributed request, domain ontology},
location = {Tetouan, Morocco},
series = {SCA '18}
}

@inproceedings{10.1145/3387940.3392212,
author = {Singi, Kapil and Choudhury, Swapnajeet Gon and Kaulgud, Vikrant and Bose, R.P. Jagadeesh Chandra and Podder, Sanjay and Burden, Adam P.},
title = {Data Sovereignty Governance Framework},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392212},
doi = {10.1145/3387940.3392212},
abstract = {Data has emerged as a central commodity in most modern applications. Unregulated and rampant collection of user and usage data by applications led to concerns on privacy, trust, and ethics. This has resulted in several governments and organizations across geographies to frame laws on data (e.g., the European Union's General Data Protection Regulation (GDPR)) that govern and define boundaries for the storage, processing and transitioning of data; and thereby safeguard the interests of its citizens. Data Sovereignty and Data Localization are two important aspects, which deal with the adherence to the laws and governance structures, that define where and how data is collected and processed. The applicability of different laws depends upon several attributes such as the nature, type, and purpose of data. Non-compliance to laws/regulations can lead to serious repercussions for enterprises, ranging from hefty penalties to loss of brand value. Ensuring that all of their applications are complaint to various laws and regulations is non-trivial. Enterprises have to deal with a plethora of laws (that are constantly evolving) and are often confused even in correctly identifying all the applicable laws for their context leave alone ensuring compliance to regulations. Therefore, in this paper, we propose a knowledge graph based data sovereignty governance framework that assists in classifying data and in identifying the relevant applicable laws.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {303–306},
numpages = {4},
keywords = {Classification, Cloud Computing, Data Sovereignty, Governance, Knowledge Graph},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3660043.3660223,
author = {Wang, Yonghua and Ma, Yanfei},
title = {Dynamic Scheduling of Multi-module Resources in Online Courses for Personalized Learning},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660223},
doi = {10.1145/3660043.3660223},
abstract = {With the rapid growth of cloud computing, Massive Open Online Courses (MOOCs) have gained popularity. However, current MOOCs platforms encounter challenges in personalized learning due to disorganized resources, and the inability to capture dynamic learning demands. We present a dynamic scheduling system for multi-module cloud course resources using deep reinforcement learning. Specifically, a knowledge graph and conceptualization ability model are constructed to evaluate students' knowledge mastery levels. The dynamic demands are modeled as Markov Decision Processes, and optimized matching strategies are derived via deep Q-learning to satisfy personalized requirements. A reward function is designed to maximize students' knowledge conceptualization ability. Comprehensive experiments on real-world datasets demonstrate the effectiveness of the proposed system. This work provides a new intelligent solution to adaptively schedule cloud course resources. The core innovations lie in accurate dynamic modeling, and adaptive resource provisioning strategies for personalized learning.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {1008–1012},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.5555/3566055.3566086,
author = {El-Darieby, Mohamed and Daoud, George and Patel, Monil},
title = {Autonomous Vehicles Technology Stack &amp; Generated Data},
year = {2022},
publisher = {IBM Corp.},
address = {USA},
abstract = {This workshop discusses, presents, and demos examples of how advances in Connected and Autonomous Vehicles (CAV) and in Information and Communications Technologies (ICT) will benefit Intelligent Transportation Systems (ITS). CAV technologies provide an enormous opportunity to generate and collect traffic datasets that directly impact Highway Traffic Management Operations (HTOps). CAV provides novel datasets in terms of types and pervasiveness of coverage of highway networks at a scale that we have not been exposed to before. This enables current HTOps for extensions in features and enhancements in accuracies. HTOps, as defined by Canadian ITS architecture [1], aims at managing traffic to enhance the efficiency of highways, avoid congestion, increase the safety of travelers, and enable more sustainable transportation. This workshop focuses on answering the following question “What (and How) are the features of CAV-generated data that can leverage (HTOps)?” We compare CAV-generated data to traditional traffic data (those collected from relatively “fixed location” sources such as CCTV, electronic loop detectors) and those collected from probe floating vehicles.Extensive research has been conducted into creating self-driving cars that can drive and maneuver on roads in a safe manner. This is embodied in the development of advanced safety features that include blind spot information, reversing/ parking/ lane change assistance, collision warning, and more. CAV can make movement actions based on knowledge of surroundings which relies on hundreds of thousands of data points collected from embedded sensors (LiDAR, cameras, radars, OBD unit, an IMU), (estimated at) a few Terabytes/Vehicle/Day. For example, Volvo’s Cirrus [2] and Lyft Level 5 [3] open-sourced datasets make use of high-resolution video cameras as well as LiDAR sensors to produce Gaussian points that monitor vehicle 3600 surroundings.As an example HTOPS service, we discuss in detail Variable Speed Limits (VSL) and how CAV data can be used to optimize maximum travel speed limit in a dynamic manner over different highway zones based on traffic, congestion, and weather. VSL helps achieve the objectives of HTOps, including devising premeditated plans for peak hours operations and controlling the travel speed in order to increase the throughput of vehicles. To increase safety and ensure compliance, gradual implementation through increments/ decrements of speed along highway zones is required. The extent, expressiveness and quality of CAV data can help achieve such advanced HTOps. For example, the nuScenes dataset [4] that uses linked data to break down and simplify data schema (with various objects such as Category, Ego Pose, Instance, Lidarseg, Map, Sample_annotation, and Sample Data.) With the help of distance measurements, space headings can be accurately defined for vehicles in front and behind the main car. In addition, current vehicle speed data can be obtained from onboard in real-time. This can also be extended to other HTOps services such as Dynamic Lane Management (DLM) which sets lane allocation rules based on the given traffic state, assigning a lane(s) to a prioritized class of vehicle or assigning variable travel speeds for each lane.CAV manufacturers and researchers have made significant progress in building a CAV technology stack that allows a vehicle to drive itself in a safe manner. The technology stack consists of sensing (described above), perception, prediction, and planning layers. The higher three layers use sophisticated deep learning machine learning to process collected data and produce further information on highway traffic conditions. For example, with camera footage, object (e.g. pedestrians, vehicles, traffic signs) detection software can be applied to identify, categorize and characterize surrounding objects. At the same time, LiDAR data can be mapped to provide a bird’s eye spatial view of the surrounding area. Such semantic object maps with binding boxes on objects and trajectory lines are valuable data that TMCs can use to understand the current roadway environment. This is important for understanding stopping time, and congestion levels between cars on the highway provided the current lane of the vehicle. However, due to how recent such developments are, the focus has been on developing the sensing and perception layers of that stack, with much less focus given to the prediction and planning layers.},
booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
pages = {227–228},
numpages = {2},
keywords = {Cloud computing, microservices, artificial intelligence, cloud operations},
location = {Toronto, Canada},
series = {CASCON '22}
}

@inproceedings{10.1145/3151759.3151776,
author = {Magdy, Abdelkader and Mohamed, A. Baith and Quirchmayr, Gerald and Schikuta, Erich},
title = {Towards a security and privacy protection model for semantic query engines},
year = {2017},
isbn = {9781450352994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3151759.3151776},
doi = {10.1145/3151759.3151776},
abstract = {The semantic web aims to describe information in terms of well-defined vocabularies and comprehends both data and knowledge to cope with meaning of data. Advanced search engines are used to retrieve precise information out of these knowledge resources. The main challenge is not only retrieving data but also how to keep data safe and protected against any form of attacks.In this paper, we propose a security aware based model for semantic search engines. Our work aims to combine advances in information technology, such as cloud technology, while addressing security issues which threaten the integrity of information. In particular security gaps and countermeasures of the semantic web are identified. ISO/IEC security requirements for the protection of personally identifiable information (PII) are presented to cover security vulnerabilities of the proposed model. Finally, the feasibility of our proposed model is checked against the N2Sky use case, a multi-cloud knowledge information management system for the computational intelligence community.},
booktitle = {Proceedings of the 19th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {198–207},
numpages = {10},
keywords = {OWL, RDF, authentication, authorization, cryptography, semantic web},
location = {Salzburg, Austria},
series = {iiWAS '17}
}

@inproceedings{10.1145/3219104.3219159,
author = {Marini, Luigi and Gutierrez-Polo, Indira and Kooper, Rob and Satheesan, Sandeep Puthanveetil and Burnette, Maxwell and Lee, Jong and Nicholson, Todd and Zhao, Yan and McHenry, Kenton},
title = {Clowder: Open Source Data Management for Long Tail Data},
year = {2018},
isbn = {9781450364461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219104.3219159},
doi = {10.1145/3219104.3219159},
abstract = {Clowder is an open source data management system to support data curation of long tail data and metadata across multiple research domains and diverse data types. Institutions and labs can install and customize their own instance of the framework on local hardware or on remote cloud computing resources to provide a shared service to distributed communities of researchers. Data can be ingested directly from instruments or manually uploaded by users and then shared with remote collaborators using a web front end. We discuss some of the challenges encountered in designing and developing a system that can be easily adapted to different scientific areas including digital preservation, geoscience, material science, medicine, social science, cultural heritage and the arts. Some of these challenges include support for large amounts of data, horizontal scaling of domain specific preprocessing algorithms, ability to provide new data visualizations in the web browser, a comprehensive Web service API for automatic data ingestion and curation, a suite of social annotation and metadata management features to support data annotation by communities of users and algorithms, and a web based front-end to interact with code running on heterogeneous clusters, including HPC resources.},
booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing: Seamless Creativity},
articleno = {40},
numpages = {8},
keywords = {data curation, data management, linked data, metadata management, scientific gateways},
location = {Pittsburgh, PA, USA},
series = {PEARC '18}
}

@inproceedings{10.1145/3012071.3012076,
author = {Reffad, Hamza and Alti, Adel and Roose, Philippe},
title = {Cloud-based semantic platform for dynamic management of context-aware mobile ERP applications},
year = {2016},
isbn = {9781450342674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3012071.3012076},
doi = {10.1145/3012071.3012076},
abstract = {Mobile cloud computing (MCC) has attracted more and more attention from both Small and Medium Enterprises (SMEs). MCC provides access to cloud services for mobile devices. With the growing popularity of smart mobile devices, customers need efficient and new high quality services. In this context, mobile ERP services management and adaptation at real time are becoming a challenging task. However, it is necessary to handle in a dynamic intelligent and transparent platform various mobile cloud services provided by multiple cloud providers with several qualities. This paper presents CloudCxQERP platform, which is a cloud-based semantic platform for dynamic management of context-aware mobile ERP applications. It is based on semantic web technologies and cloud computing and provides fast ERP development process and "an ecosystem" of enterprises that ensures quality customer service. Moreover, our platform provides a middleware that offers to users more efficient services corresponding to current situations and adapts its ERP applications more quickly and cost effectively. Experiments are based on online packaging boxes services.},
booktitle = {Proceedings of the 8th International Conference on Management of Digital EcoSystems},
pages = {181–188},
numpages = {8},
keywords = {ERP, QoS, cloud, context-aware, multi-enterprises profiles, semantic virtual business services},
location = {Biarritz, France},
series = {MEDES}
}

@inproceedings{10.1145/3030024.3040248,
author = {Celik, Ilknur and Torre, Ilaria},
title = {IUI'17 Workshop Summary for SmartLearn: Intelligent Interfaces for Ubiquitous and Smart Learning},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040248},
doi = {10.1145/3030024.3040248},
abstract = {New technologies are changing the way we learn and teach. Emerging technologies such as social semantic web, cloud computing, and the growing popularity of mobile devices, embedded devices and adaptive context-aware technologies are leading to a paradigm shift in the way educational services are provided. Through technologies and approaches such as ubiquitous and adaptive learning, learning becomes personalized, flexible, and suitable to meet diverse and rapidly changing technologies, environments and learner needs, while opening unprecedented possibilities for education. The aim of the "Intelligent Interfaces for Ubiquitous and Smart Learning" workshop has been to bring together researchers from industry and academia to address the challenges of the intelligent user interfaces and smart learning fields, discuss new ideas and present their research to the scientific community in order to enhance the methodologies and techniques for intelligent learning environments for the 21st century. The workshop program, program committee and further details are available on the website (http://smartlearn.dibris.unige.it/).},
booktitle = {Companion Proceedings of the 22nd International Conference on Intelligent User Interfaces},
pages = {17–19},
numpages = {3},
keywords = {cloud technologies, intelligent interfaces, intelligent tutoring systems, interactive learning environments, mobile learning, personalized interaction, recommender systems, smart educational interfaces, social and semantic technologies, technology-enhanced learning, ubiquitous learning, user modelling, user-adapted systems, workshop},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.5555/2872518.3251208,
author = {Cuzzocrea, Alfredo and El Saddik, Abdulmotaleb},
title = {Session details: Demonstrations},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {It is our great pleasure to welcome you to the Demo Track of WWW 2016, The 25th International World Wide Web Conference, held in Montreal, Canada, during April 11-15, 2016.The WWW 2016 Demo Track, like in the tradition of WWW Demo conference series, allows researchers and practitioners to demonstrate new systems in a dedicated session. Demo contributions are based on an implemented and tested system that pursues one or more innovative ideas in the interest areas of Web data and information management, Web search, Web intelligence tools, Web mining, social network applications and so forth. Topics of interest for the 2016 edition's conference include (but are not limited to) the following ones: Behavioral Analysis and PersonalizationBig Data on the WebCrowdsourcing Systems and Social MediaContent AnalysisGraph Data Management and MiningHigh-Performance Infrastructures for Data- Intensive Web TasksInternet Economics and MonetizationPervasive Web and MobilitySecurity and PrivacySemantic WebSocial Networks and Graph AnalysisWeb Information RetrievalWeb Infrastructure: Datacenters, Content Delivery Networks, and Cloud ComputingWeb MiningWeb ScienceWeb Search Systems and ApplicationsDemo contributions come from academic researchers, industrial practitioners with prototypes or inproduction deployments, as well as from any W3C-related activities. All have in common to show innovative use of Web-based techniques.The WWW 2016 Demo Track call for papers attracted 65 submissions from all over the world (USA, North America, South America, Europe, Australia, Asia, Africa). The program committee reviewed and accepted a very selected collection of 29 papers, and the final statistics is the following: WWW 2016 Demo Track Statistics Number of Submitted Papers 65 Number of Accepted Papers 29.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}


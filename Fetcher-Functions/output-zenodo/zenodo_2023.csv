title,authors,abstract,year,keywords,doi,url,type
A Novel Approach for Healthcare Information System using Cloud,"R. Jeena, G. Dhanalakshmi, S. Irin Sherly, S. Ashwini, R. Vidhya","<p><strong>Abstract</strong>: The main objective of this paper is to outline a Cloud Computing based Healthcare Information System that helps bridge the gap between various hospitals, patients and clinics by creating a central hub of patient details and health care history that is accessible via two interfaces- either the mobile app or the web application.</p>",2023,Cloud Computing.,10.35940/ijrte.F5327.039621,,publication
Towards a Knowledge Graph Enhanced Automation and Collaboration Framework for Digital Twins,"Christou, Vasileios, Wang, Yuandou, Zhao, Zhiming","<p><em>The Digital Twin (DT) provides a digital representation</em></p>

<p><em>of a physical system and allows users to interactively study</em></p>

<p><em>the physical processes of a real system via the digital representation</em></p>

<p><em>in different scenarios in real time. The development</em></p>

<p><em>of a DT is highly complex; it requires not only expertise from</em></p>

<p><em>multiple disciplines but also the integration of often heterogeneous</em></p>

<p><em>software components, e.g., simulations, machine learning,</em></p>

<p><em>visualization, and user interface components across distributed</em></p>

<p><em>environments. This poster presents a Knowledge Graph-based</em></p>

<p><em>ontological framework to boost automation and collaboration</em></p>

<p><em>during the DT lifecycle stages. We implement our methods in</em></p>

<p><em>developing a what-if analysis service for a DT of an ecosystem</em></p>

<p><em>of wetlands and its automated deployment to the Amazon Web</em></p>

<p><em>Services (AWS) cloud.</em></p>",2023,"Digital Twin, Semantic Web, Knowledge Graph, Ontology, Cloud Computing, What-If Analysis",10.1109/E-SCIENCE58273.2023.10254845,,publication
Towards Graph-based Cloud Cost Modelling and Optimisation,"Khan, Akif Quddus, Nikolov, Nikolay, Matskin, Mihhail, Prodan, Radu, Bussler, Christoph, Roman, Dumitru, Soylu, Ahmet","<p>Cloud computing has become an increasingly popular choice for businesses and individuals due to its flexibility, scalability, and convenience; however, the rising cost of cloud resources has become a significant concern for many. The pay-per-use model used in cloud computing means that costs can accumulate quickly, and the lack of visibility and control can result in unexpected expenses. The cost structure becomes even more complicated when dealing with hybrid or multi-cloud environments. For businesses, the cost of cloud computing can be a significant portion of their IT budget, and any savings can lead to better financial stability and competitiveness. In this respect, it is essential to manage cloud costs effectively. This requires a deep understanding of current resource utilization, forecasting future needs, and optimising resource utilization to control costs. To address this challenge, new tools and techniques are being developed to provide more visibility and control over cloud computing costs. In this respect, this paper explores a graph-based solution for modelling cost elements and cloud resources and potential ways to solve the resulting constraint problem of cost optimisation. We primarily consider utilization, cost, performance, and availability in this context. Such an approach will eventually help organizations make informed decisions about cloud resource placement and manage the costs of software applications and data workflows deployed in single, hybrid, or multi-cloud environments.</p>",2023,"Cloud computing, Costs, Computational modeling, Scalability, Organizations, Software, Stability analysis",10.1109/COMPSAC57700.2023.00203,,publication
Application of machine learning methods for filling and updating nuclear knowledge bases,"Telnov, Victor P., Korovin, Yury A.","<p>The paper deals with issues of designing and creating knowledge bases in the field of nuclear science and technology. The authors present the results of searching for and testing optimal classification and semantic annotation algorithms applied to the textual network content for the convenience of computer-aided filling and updating of scalable semantic repositories (knowledge bases) in the field of nuclear physics and nuclear power engineering and, in the future, for other subject areas, both in Russian and English. The proposed algorithms will provide a methodological and technological basis for creating problem-oriented knowledge bases as artificial intelligence systems, as well as prerequisites for the development of semantic technologies for acquiring new knowledge on the Internet without direct human participation. Testing of the studied machine learning algorithms is carried out by the cross-validation method using corpora of specialized texts. The novelty of the presented study lies in the application of the Pareto optimality principle for multi-criteria evaluation and ranking of the studied algorithms in the absence of a priori information about the comparative significance of the criteria. The project is implemented in accordance with the Semantic Web standards (RDF, OWL, SPARQL, etc.). There are no technological restrictions for integrating the created knowledge bases with third-party data repositories as well as metasearch, library, reference or information and question-answer systems. The proposed software solutions are based on cloud computing using DBaaS and PaaS service models to ensure the scalability of data warehouses and network services. The created software is in the public domain and can be freely replicated.</p>",2023,"semantic web, knowledge base, machine learning, classification, semantic annotation, cloud computing",10.3897/nucet.9.106759,,publication
The Impact of Cloud Computing on Small and Medium-Sized Businesses,"Bismah Nazim Killedar, Maaz Zahid Datey","<p>Cloud computing has had a significant impact on small and medium-sized businesses (SMBs).<br>
The benefits of cloud computing adoption, including cost savings, scalability, flexibility, and improved data<br>
security, have made this technology increasingly popular among SMBs. However, several challenges<br>
prevent SMBs from adopting cloud computing, including a lack of technical knowledge and expertise,<br>
security concerns, and concerns around the reliability and availability of cloud computing services. Despite<br>
these challenges, many SMBs have successfully implemented cloud computing and have seen significant<br>
improvements in their operations. Case studies have shown that SMBs that migrated to cloud-based<br>
services experienced a reduction in IT costs and an increase in revenue. Additionally, SMBs that adopted<br>
cloud computing services saw a reduction in downtime and improved disaster recovery capabilities. The<br>
impact of cloud computing on SMBs extends beyond operational improvements. Cloud computing has also<br>
improved the competitiveness and profitability of SMBs, enabling them to access enterprise-grade<br>
technology at an affordable cost and allowing them to scale their operations quickly and efficiently. Cloud<br>
computing has also enabled SMBs to compete with larger businesses by providing them with the same<br>
technological capabilities. Cloud computing has had a significant impact on SMBs by providing them with<br>
cost-effective access to enterprise-grade technology, improving operational efficiency, and enhancing<br>
competitiveness and profitability. While several challenges prevent SMBs from adopting cloud computing,<br>
successful implementation can bring significant benefits to their operations</p>",2023,,10.5281/zenodo.8133455,,publication
Role of Cloud Computing for Improvement in  Healthcare Services,Dr. Puja Shashi,"<p><strong>Abstract:</strong> Cloud helps in offering on-demand latest technology that helps in deploying, accessing and using network-accessed information along with various applications and resources. Nowadays electronic health records are maintained by many hospitals that want to undergo a change in their legacy system. This type of transformation has helped physicians, nurses and also administrative staff access the desired record whenever needed. They believe that this may change the complete face of health information technology. However, lack of security and privacy are two important concerns that may provide hazards when choosing cloud solutions for various health-related factors. This problem can be avoided to some extent by evaluating cloud technology in an effective manner before its complete adoption. This paper uses four major aspects i.e., technology, security, legal and management for finding different types of challenges of this computing model. When any health services want to migrate from traditional to cloud-based health services then they can do different types of strategic planning for determining strategy, allocated resources and direction for maintaining a cloud environment in their organization.</p>",2023,"Electronic health record (1), Cloud computing (2),  Health care(1), quality improvement (3)",10.35940/ijrte.B7133.0711222,,publication
SECURE CLOUD COMPUTING MECHANISM FOR ENHANCING: MTBAC,"Payal Buha, Priyanka Sharma","<p>The development of the cloud system,A large number of vendors can visit their users in the same platform directing their focus on the software rather than the underlying framework. This necessary require the distribution, storage analysis of the data on cloud accessing virtualized and scalable web services with broad application of cloud, the data security and access control become a major concern. The access to the cloud requires authorization as well as data accessibility permission. The verification and updation of data accessibility permissions and data must be done with proper knowledge which requires identification of correct updates and block listed users who are intruder to cloud Introducing the false data system. In this paper we approach to builds a mutual trust relationship between users and cloud for accessing control method in cloud computing environment focusing on the system integrity and its security. The proposed approach is executed as a procedure manner and includes many steps to identify the user&rsquo;s credibility in the cloud network.</p>",2023,"MTBAC, ACO Algorithm, Access Control, Security, K-means Algorithm, Cloud Computing",10.5281/zenodo.8045720,,publication
Modeling and Simulation of Real-Time Virtual Machine Allocation in a Cloud Data Center,S. Jason,"<p><strong>Abstract: </strong>For dynamic resource scheduling in cloud data centers, a novel lightweight simulation system is proposed; two existing simulation systems at the application level for cloud computing are reviewed; and results gained using the suggested simulation system are examined and discussed. The usage of resources and energy efficiency in cloud data centers can be improved by load balancing and the consolidation of virtual machines. An aspect of dynamic virtual machine consolidation that directly affects resource usage and the quality of service the system is delivering is the timing of when it is ideal to reallocate Virtual Machines from an overloaded host [1]. Because server overloads result in a lack of resources and a decline in application performance, they have an impact on quality of service. In order to determine the best answer, existing approaches to the problem of host overload detection typically rely on statistical analysis inspired by nature. These strategies&#39; drawbacks include the fact that they provide less-than-ideal outcomes and prevent the explicit articulation of a Quality-of-Service target. By optimizing the mean inter-migration time under the defined Quality of Service target ideally, we present a novel method for detecting host overload for any stationary workload that is known and a particular state configuration [2]. We demonstrate that our technique exceeds the best benchmark algorithm and offers over 88%of the performance of the ideal offline algorithm through simulations with real-world workload traces from more than a thousand Virtual Machines.</p>",2023,Cloud Computing; Data Centers; Dynamic Resource Scheduling; Lightweight Simulation System,10.35940/ijeat.E4182.0612523,,publication
Cloud computing virtual learning environment: issues and challenges,"Aminah Rezqallah Malkawi, Muhamad Shahbani Abu Bakar, Zulkhairi Md Dahlin","<p>Cloud computing (CC) is a popular technology that has demonstrated its usefulness and effectiveness across industries and sectors worldwide. As a result, several educational institutions have recently integrated CC into their platforms and systems, including their virtual learning environment (VLE). In order to highlight the issues, challenges, and requirements to be taken into account before implementing CC technology within educational institutions, it is imperative to conduct a study to investigate the level of awareness, knowledge, and acceptance of the targeted users, who are educators, learners, and administrators of higher education institutions (HE). The result of the study highlighted some concerns facing users from 35 different institutions around the kingdom of Saudi Arabia. In addition, results highlighted the users&#39; training, awareness, technology infrastructure, and cultural influences as factors to consider before adopting a sustainable and usable CC-VLE.</p>",2023,"Challenges, Cloud computing, E-learning platforms, Higher educational institutions, Virtual learning environment",10.11591/ijeecs.v30.i3.pp1707-1712,,publication
Proficient Machine Learning Techniques for a Secured Cloud Environment,"Majjaru Chandrababu, Dr. Senthil Kumar K","<p><strong>Abstract: </strong>Many different checks, rules, processes, and technologies work together to keep cloud-based applications and infrastructure safe and secure against cyberattacks. Data security, customer privacy, regulatory enforcement, and device and user authentication regulations are all protected by these safety measures. Insecure Access Points, DDoS Attacks, Data Breach and Data Loss are the most pressing issues in cloud security. In the cloud computing context, researchers looked at several methods for detecting intrusions. Cloud security best practises such as host &amp; middleware security, infrastructure and virtualization security, and application system &amp; data security make up the bulk of these approaches, which are based on more traditional means of detecting abuse and anomalies. Machine Learning-based strategies for securing cloud infrastructure are the topic of this work, and ongoing research comprises research issues. There are a number of unresolved issues that will be addressed in the future.</p>",2023,"Cloud Computing, Anomaly Detection, Machine Learning Approaches, Supervised Learning and Unsupervised-Learning.",10.35940/ijeat.F3730.0811622,,publication
HOCC: An ontology for holistic description of cluster settings,"Poulakis, Yannis, Fatouros, Georgios, Kousiouris, George, Kyriazis, Dimosthenis","<div>
<div>
<div>
<p>Ontologies have become the de-facto information represen- tation method in the semantic web domain, but recently gained popu- larity in other domains such as cloud computing. In this context, ontolo- gies enable service discovery, effective comparison and selection of IaaS, PaaS and SaaS offerings and ease the application deployment process by tackling what is known as the vendor lock-in problem. In this paper we propose a novel ontology named HOCC: holistic ontology for effec- tive cluster comparison. The ontology design process is based on four different information categories, namely Performance, SLA, cost and en- vironmental impact. In addition we present our approach for populating, managing and taking advantage of the proposed ontology as developed in a real world Kubernetes cluster setting, as well as instantiating the ontology with example services and data (namely performance aspects of a serverless function).</p>
</div>
</div>
</div>",2023,,10.5281/zenodo.10401131,,publication
Emerging Trends of web Mining Through Cloud Mining (Bitcoin) in Business Companies,Dr. Nirmla Sharma,"<p><strong>Abstract:</strong> In this paper we show research about how to mine valuable knowledge on the web mining through cloud mining in business companies and comparison about web mine. This paper illustrates the recent, previous, and upcoming web mining by cloud mining. Now we initiate real-time data set for recovery facts on the network i.e., web content mining, and the detection of client approach relationships from cloud servers, i.e., web management mining that enhance the web mining problems. Moreover, we similarly illustrated web mining through cloud mining in business companies. Cloud mining is an upcoming Web Mining. That is the main benefit of the company looking after all the usual mining problems. Cloud mining decreases the costs correlated with running a mining rig. Cloud mining is a procedure to mine cryptocurrency like bitcoin, by leased cloud computing operate without connecting or promptly governing the hardware and associated software. The initial processor that has observed a result to the problem catches the succeeding Bitcoin block, and the procedure remains. Bitcoin mining needs advanced hardware to explain difficult calculations and arithmetic challenges. In this paper we have discussed to work and is beneficial for business companies. We have proposed a structure for a cloud mining service. These services are supported by business model and strategy, hardware procurement and setup, user interface and dashboard and customer support and education etc. Cloud mining service deals are often tricks, or rip-offs. Cloud mining suppliers and companies benefit by leasing away their hardware in replace for funds. Trading mining hardware seems like a prospect&rsquo;s agreement for saving ruses.</p>",2023,"Business Companies, Cryptocurrency Mining, Cloud Mining, Cloud Mining Models, And Web Mining",10.35940/ijeat.B4319.1213223,,publication
Public Sector Cloud Computing Adoption and Utilization During Covid-19: An Agenda for Research and Practice,Mark Theby,"<p>Cloud computing became a pivotal crisis response tool for many public sector organizations (PSOs) during the COVID-19 pandemic, sustaining public service delivery and public sector operations during times of extraordinary global turmoil. The technology&rsquo;s inherent strengths of flexibility, innovation, resilience, and collaboration prompted PSOs to aggressively pursue both the initial adoption of cloud and the expansion of already-existing cloud computing capabilities. Despite the importance of the emerging topic of crisisdriven public sector cloud adoption for future crisis response efforts and the post-crisis transition to regular public sector operations, academic literature and empirics are sparse and present a distinct knowledge gap. This article assesses crisis-driven public sector cloud computing adoption and expanded utilization and provides recommendations for the advancement of research and practice, supporting future research, collaboration, and evidence-based cloud computing implementation and utilization.</p>",2023,,10.5281/zenodo.8068290,,publication
Comparing performance of bastion host on cloud using Amazon web services vs terraform,"Sahana Bailuguttu, Akshatha S. Chavan, Oorja Pal, Kavya Sannakavalappa, Dipto Chakrabarti","<p>In addition to security advantages like implementing defense in depth and complying with compliance standards, current bastion services are simple to deploy and fit into the DevOps culture. Bastions continue to be the most dependable and secure options for secure access to cloud infrastructures because they offer administrative simplicity without surrendering compliance and security. In this paper, an experimental set up was conducted to measure the cycle time it takes to provision resources using manual point-and-click graphical user interface (GUI) in Amazon web services (AWS) and time it takes for codified infrastructure to make application programming interface (API) calls using terraform. It also focuses on the design and deployment of Bastion host on AWS and terraform, and the comparison between the two with respect to various parameters.</p>",2023,"Amazon elastic cloud computing, Amazon web services, Bastion host, Cloud computing, Firewall, Terraform",10.11591/ijeecs.v30.i3.pp1722-1728,,publication
Cloud Security: Challenges and Future Scope,"Priyanka Vashisht, Shalini Bhaskar Bajaj, Aman Jatain, Ashima Narang","<p>Now Cloud computing becomes so much popular coz satisfying business needs efficiently. Cloud features provide best lead to organizations to effectively access data and services with less cost over the internet. This also raise issues related with cloud security. This paper presents brief information regarding cloud computing security challenges. This information includes security mechanisms that should be consider for Cloud Service Models. This Work also focus on detail knowledge of security issues, threats which may use by attacker. It also explains cloud components levels threats and attack so more secure mechanism can identified for each component. This Paper introduced classification of Cloud security areas issues to develop secure Cloud Security services in future.</p>",2023,"Cloud Computing, Cloud Security, Threats, Security issues, Data protection, Attacks",10.5281/zenodo.8114265,,publication
Cloud Computing: A New Way of Information Management in Academic Libraries,Dr. Sanjay B.Munavalli,"<p>The globalisation of information and knowledge resources has been influenced by the growing use and applications of information and communication technology (ICT). Instead of using local servers or personal devices to handle applications, cloud computing relies on the sharing of computing resources. Libraries are passing through a stage when their budgets are shrinking considerably and users demands are multiplying manifolds. Cloud deployment will go up significantly in the next few years. Libraries would integrate cloud based services in their agenda.</p>",2023,,10.5281/zenodo.7578049,,publication
Sharing costs of cross-border computing resources for beautiful climate data,"Fouilloux, Anne, Iaquinta, Jean, Landgren, Oskar, Dwarakanath, Prashanth, Abdulrahman, Azab","<p>This paper is part of the &nbsp;Fast Track to&nbsp;Vision 2030 publication that is a collection of policy brief articles written by Nordic researchers participating in collaborative projects funded by NordForsk or Nordic Energy Research.&nbsp;</p>

<p>&nbsp;</p>

<p>All the articles published in the&nbsp;Fast Track to&nbsp;Vision 2030 are available at&nbsp;<a href=""https://www.nordforsk.org/2023/fast-track-vision-2030"">https://www.nordforsk.org/2023/fast-track-vision-2030</a>, including this paper.</p>

<p>NordForsk is aiming for this publication to contribute relevant and up-to-date research-based knowledge that facilitates the analysis of the challenges and opportunities of Nordic co-operation in the coming years.&nbsp;</p>

<p>The articles are original and written in April and May 2023 in response to a NordForsk call for policy brief articles to invited researchers and research groups.</p>",2023,"climate, cloud computing, cross-border computing, Nordic",10.5281/zenodo.8311316,,publication
A Multi-faceted Analysis of the Performance Variability of Virtual Machines,"Luciano Baresi, Tommaso Dolci, Giovanni Quattrocchi, Nicholas Rasi","<p>Cloud computing and virtualization solutions allow one to rent the virtual machines (VMs) needed to run applications on a pay-per-use basis, but rented VMs do not offer any guarantee on their performance. Cloud platforms are known to be affected by performance <em>variability</em>, but a better understanding is still required.<br>
This paper moves in that direction and presents an in-depth, multi-faceted study on the performance variability of VMs. Unlike previous studies, our assessment covers a wide range of factors: 16 VM types from 4 well-known cloud providers, 10 benchmarks, and 28 different metrics. We present four new contributions. First, we introduce a new benchmark suite (<em>VMBS</em>) that let researchers and practitioners systematically collect a diverse set of performance data. Second, we present a new indicator, called <em>Variability Indicator</em>, that allows for measuring variability in the performance of VMs. Third, we illustrate an analysis of the collected data across four different dimensions: <em>resources</em>, <em>isolation</em>, <em>time</em>, and <em>cost</em>. Fourth, we present multiple predictive models based on Machine Learning that aim to forecast future performance and detect time patterns. Our experiments provide important insights on the resource variability of VMs, highlighting differences and similarities between various cloud providers. To the best of our knowledge, this is the widest analysis ever conducted on the topic.</p>",2023,"Cloud computing, Virtual machines, Software performance, Software reliability",10.5281/zenodo.8014668,,publication
Virtual machine tree task scheduling for load balancing in cloud computing,"Santosh Kumar Maurya, Suraj Malik, Neeraj Kumar","<p>The increasing number of publications towards cloud computing proves that much research and development has been done, especially for task scheduling. Organizations are eager to get more customized technology to run the most smoothly in the provision of visual cloud services for fruity users. As the circumstances of Covid indicate to technology that everyone should run digitally, the workload on machines increased. For workload solutions, organizations are trying to balance the situation with the successful operation of cloud services to use appropriate services/resources. Nevertheless, the issues are still to be resolved by researchers, so we respect all my friends who are putting a lot of effort into developing new techniques. A proposed paper is showing a new collation with the load balancing factor by implementing quality of service (QoS) and virtual machine tree (VMT). A CloudSim toolkit will then be used to compare them. A tree structure graph is included in the VMT algorithm to schedule tasks with the appropriate distribution on each machine. The QoS algorithm performs the task of scheduling based on the service required by the user with the best quality and satisfies the user.</p>",2023,"Cloud computing, Load balancing, Quality of service, Task scheduling, Virtual machine tree",10.11591/ijeecs.v30.i1.pp388-393,,publication
A Cloud-Based Platform for Service Restoration in Active Distribution Grids,"Haghgoo, Maliheh, Dognini, Alberto, Monti, Antonello","<p>In modern distribution grids, the access to the growing amount of data from various sources, the execution of complex algorithms on-demand, and the control of sparse actuators require on-demand scalability to support fluctuating workloads. Cloud computing technologies represent a viable solution for these requirements. To ensure that data can be exchanged and shared efficiently, as well as the full achievement of the cloud computing benefits to support the advanced analytic and mining required in smart grids, applications can be empowered with semantic information integration. This article adopts the semantic web into a cloud-based platform to analyze power distribution grids data and apply a service restoration application to re-energize loads after an electrical fault. The exemplary implementation of the demo is powered by FIWARE, which is based on open-source and customizable building blocks for future internet applications and services, and the SARGON ontology for the energy domain. The tests are deployed by integrating the semantic information, based on the IEC 61850 data model, in the cloud-based service restoration application and interfacing the field devices of the distribution grids. The platform performances, measured as network latency and computation time, ensure the feasibility of the proposed solution, constituting a reference for the next deployments of smart energy platforms.</p>",2023,"Smart Energy Platform, Service-oriented, Middleware, FIWARE, Service restoration, Cloud-based platform,, Semantic web, Publication, European Union (EU), H2020 Project, HYPERRIDE, GA 957788",10.1109/TIA.2022.3142661,,publication
Mental Health problem prediction of Tech Employees Using Machine Learning,"Siddharth Gupta, Pratibha Barua, Akanksha Kochhar, Vijay kumar, Rachna Narula","<p><em>In this era rapid societal changes, in addition to technology improvements, might pose problems and stress for the future generations. Individuals and society as a whole must place a high priority on mental health and well-being in order to reduce the detrimental effects of these developments. Individuals should give more importance to their own particular ideals and ambitions than just keeping up with society&#39;s pace. This kernel&#39;s goal is to identify the factors that affect someone&#39;s mental health based on this dataset. In 2014, attitudes towards mental health as well as the prevalence of mental health issues in the tech industry were assessed. This kernel seeks to create a methodical approach to comprehending mental Health in the workplace, in contrast to the other kernels. Is there a preliminary action that must be taken? There are typically many creative kernels on many issues, but only a small number are dedicated to addressing the issues of how to start on issues in medicine, particularly those relating to local knowledge. This section outlines prostate cancer and how to identify it. Additionally, we have completed Electronic Design Automation, created a dataset, and established a dataset.</em></p>",2023,"Mental health, Logistic Regression, K-nearest Neighbor Classifier, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, Artificial Neural Network",10.5281/zenodo.8337193,,publication
National Cloud Strategy 2023,"Digital Research Alliance of Canada, National Cloud Strategy Working Group","<p>The Digital Research Alliance of Canada exists to serve Canadian researchers – ultimately propelling Canada onto the international stage as a leader in the knowledge economy. Its coordination and funding of activities in advanced research computing (ARC), research data management (RDM) and research software (RS) will benefit Canadian researchers. This document establishes and communicates the organisation's unified cloud computing adoption strategy and direction. It identifies high-level approaches and methodologies upon which all impacted stakeholders agree.</p>",2023,"ARC, Advanced Research Computing, Capital Expenditure, CAPEX, Cloud Computing, Community Cloud, Commercial Cloud, Cloud Service Providers, CSPs, Cloud Infrastructure, Cloud Service",10.5281/zenodo.10214475,,publication
B-Cubed: Leveraging analysis-ready biodiversity datasets and cloud computing for timely and actionable biodiversity monitoring,"Groom, Quentin, Abraham, Laura, Adriaens, Tim, Breugelmans, Lissa, Clarke, David, Fernández, Miguel, Hendrickx, Louise, Hui, Cang, Kumschick, Sabrina, Martini, Matilde, McGeoch, Melodie, Metodiev, Teodor, Miller, Joe, Oldoni, Damiano, Pereira, Henrique, Preda, Cristina, Robertson, Tim, Rocchini, Duccio, Seebens, Hanno, Teixeira, Heliana, Trekels, Maarten, Wilson, John Ross, Yovcheva, Nikol, Zengeya, Tsungai, Desmet, Peter","<p>Effective biodiversity management and policy decisions require timely access to accurate and reliable information on biodiversity status, trends, and threats. However, the process of data cleaning, aggregation, and analysis is often time-consuming, convoluted, laborious, and irreproducible. Biodiversity monitoring across large areas faces challenges in evaluating data completeness and quantifying sampling effort. Despite these obstacles, unprecedented amounts of biodiversity data are being accumulated from diverse sources, aided by emerging technologies such as automatic sensors, eDNA, and satellite tracking.</p><p>To address these challenges, the development of tools and infrastructure is crucial for meaningful interpretations and deeper understanding of biodiversity data (Kissling et al. 2017). Furthermore, a significant delay exists in converting biodiversity data into actionable knowledge. Efforts have been made to reduce this lag through rapid mobilisation of biodiversity observations, digitization of collections (Nelson and Ellis 2018), and streamlined workflows for data publication (Reyserhove et al. 2020). However, delays still occur in the analysis, publication, and dissemination of data.</p><p>The B-Cubed project (Biodiversity Building Blocks for Policy)*1 proposes solutions to overcome these challenges. It implements the concept of Occurrence Cubes (Oldoni et al. 2020), which aggregate occurrence data along spatial, temporal and taxonomic dimensions. Cube generation will be available as a new service provided by the Global Biodiversity Information Facility (GBIF). By leveraging aggregated occupancy cubes as analysis-ready biodiversity datasets, we aim to enhance comprehension and reduce barriers to accessing and interpreting biodiversity data. Automation of workflows will provide regular and reproducible indicators and models that are open and useful to users. Additionally, the use of cloud computing offers scalability, flexibility, and collaborative opportunities for applying advanced data science techniques anywhere. Finally, close collaboration with stakeholders will inform us of the requirements for tools, increase impact, and facilitate the flow of information from primary data to the decision-making processes.</p>",2023,"biodiversity indicator, data cubes, Global Biodiversity Information Facility, policy support",10.3897/biss.7.110734,,publication
Quantifying quantitative correlation of provider selection influences cloud security,"Azlinda Abdul Aziz, Salyani Osman, Setyawan Widyarto, Suziyanti Marjudi, Nur Razia Mohd Suradi, Rahayu Handan","<p>The cloud computing has been able to help users to access the data easily and effectively. However, cloud security is highly emphasized to cloud users to ensure data is securely stored. The cloud security can be handled well by chosen trusted cloud service provider in getting high impact on the cloud security. The relationship between cloud security with the provider selection is much needed to ensure the extent to which data is securely stored in a cloud. Therefore, in this paper the quantitative method was conducted to measure the correlation between the selected the right cloud service provider influence the cloud security. Thus, knowledgeable person in having the experiences in using the cloud service was taking from two institution of higher learning (IHL) as a respondent. In addition, variability and normality data analysis was firstly conducted to obtain the consistency of the data. Then, the correlation between cloud security factor and provider selection factor was conducted using spearman correlation matrix and scatter graph in identifying the closely and significant the value in influencing between the factors. Thus, the correlation relationship analysis result shown the selected the right cloud provider&rsquo;s give higher impact to cloud security.</p>",2023,"Cloud advantage, Cloud computing, Cloud security, Data correlation, Provider selection",10.11591/ijeecs.v31.i3.pp1642-1647,,publication
OBLEA: A New Methodology to Optimise Bluetooth Low Energy Anchors in Multi-occupancy Location Systems,"López Ruiz, José L., Verdejo Espinosa, Ángeles, Montoro Lendínez, Alicia, Espinilla Estévez, Macarena","Nowadays, it is becoming increasingly important to understand the multiple configuration factors of BLE anchors in indoor location systems. This task becomes particularly crucial in the context of activity recognition in multi-occupancy smart environments. Knowing the impact of the configuration of BLE anchors in an indoor location system allows us to distinguish the interactions performed by each inhabitant in a smart environment according to their proximity to each sensor. This paper proposes a new methodology, OBLEA, that determines the optimisation of Bluetooth Low Energy (BLE) anchors in indoor location systems, considering multiple BLE variables to increase flexibility and facilitate transferability to other environments. Concretely, we present a model based on a data-driven approach that considers configurations to obtain the best performing configuration with a minimum number of anchors. This methodology includes a flexible framework for the indoor space, the architecture to be deployed, which considers the RSSI value of the BLE anchors, and finally, optimisation and inference for indoor location. As a case study, OBLEA is applied to determine the location of ageing inhabitants in a nursing home in Alcaudete, Jaén (Spain). Results show the extracted knowledge related to the optimisation of BLE anchors involved in the case study.",2023,"Indoor location system, Bluetooth Low Energy, Fog-Cloud computing, Sustainable development goals",10.3897/jucs.96878,,publication
An Enhanced Framework To Secure Big Data  Based on Hybrid Machine Learning  Technique:ANN-PSO,Assoc. Prof. Salim Raza Qureshi,"<p><strong>Abstract:</strong> With the advancement of smart devices and cloud computing, more and more public health data can be collected from various sources and analyzed in unprecedented ways. The enormous social and academic impact of this development has led to a global buzz for bigdata. Moreover, due to the massive data source, the security of big data in the cloud is becoming an important issue. In these days, various issues have arisen in the field of big data security, such as Infrastructure security, data confidentiality, data management and data integrity. In this paper, we propose a novel technique based on Artificial Neural Network-and Particle Swarm Optimization Algorithm (ANNPSO) for enabling a highly secured framework. The ANN-PSO method was created to predict health status from a database and its functions were selected from these data sets. The particle swarm optimization algorithm matches the ANN for better results by reducing errors. The results show the potential of the ANNPSO-based methodology for satisfactory health prediction results. This proposed approach will be tested using large medical data in a Hadoop environment. The proposed work will be carried out in the JAVA work phase.</p>",2023,"ANN-PSO, Accuracy, Classifier, Error, GOA,  Health condition.",10.35940/ijrte.F5385.039621,,publication
AUTOMATION OF HEALTHCARE APPLICATIONS BY INCORPORATION OF IT,Zamira Suyunova,"<p><em>The use of modern technologies in the public, business and healthcare sectors will be examined in this work. The styles of typical behavior of the various life segments indicated above tend to change as a result of recent technology breakthroughs which also negatively impact how these segments function. The technology provides mysterious ways in the realm of automation and shines light on particular sectors that call for acceptable and excellent services. By doing this, the effectiveness of the entire system that is put in place is improved in terms of credibility and accountability. A variety of documentations that are empirically applied in the field of IT are investigated to look into how the automation of the application areas is influenced by IT regarding the equation of responsibility. The investigation goes from the most basic types of transactions which entail lesser levels of automation to highly automated systems which include, among other things, technology that analyze biometric fingerprints. In the example, the accountable potential of IT automation is discussed for the various applications with the goal of examining the advantages of application automation while removing the potentials that are unaccountable and impede the functionality that may result from the use of the systems applications on the various fields. The necessity of striking a balance between the advantages of automated IT applications and the full automation process including any system that would tend to make applications less efficient or raise questions about accountability is emphasized frequently throughout this work.</em></p>",2023,"Information Technology (IT), Automation, Accountability, Public sector, Private sector, Healthcare sector",10.5281/zenodo.7726088,,publication
Formation of a minimum viable IT project team using the genetic algorithm,"Iryna Blyznyukova, Pavlo Teslenko","<p><em>The object of research is the process of forming an IT project team, in which the development technology is based on the technology of creating a minimum viable product (MVP) and design thinking (DT) technology. Such IT projects usually have a high content of innovation and require a special management technique, as well as a special approach to the properties of the project team.</em></p>

<p><em>The application of design thinking technology will require project team members to master the property of empathy for the customer&#39;s problems. Empathy is a property of the human representational system and cannot be acquired through education or training. If it exists, then this property can be developed thanks to special training. Therefore, there is a problem regarding the formation of the IT project team. The manager who is responsible for forming the team needs to make a decision to choose between the availability of technical competencies of the applicants, the ability to work in a team, and the presence of empathy. In addition to the outlined requirements for applicants, such a team must be self-managed and self-organized. This also adds a whole series of requirements to applicants for the IT project team. Usually, applicants possessing all the necessary properties in full do not exist. Therefore, the manager (expert) will need to make decisions about compromises in meeting all the project&#39;s requirements. In addition, the need for labor resources will change during the project life cycle (PLC). It is for this purpose that it is proposed to use a genetic algorithm (GA), which will allow finding a local extremum that will be optimal under the current conditions of the project to solve a multi-criteria problem. This will reduce the subjective component in the process of making project decisions, which in turn will increase the probability of successful completion of IT projects in conditions of uncertainty and dynamic changes.</em></p>

<p><em>The proposed method of forming an IT project team can be applied in practice in the form of information technology, to which in the form of a template it will be necessary to enter information about project requirements and the competency map of applicants. As a result, the GA will propose a decision regarding the quantitative and competent composition of the project team.</em></p>",2023,"IT project, minimal viable product creation technology, design thinking technology, minimal viable team, empathy, genetic algorithm",10.15587/2706-5448.2023.277930,,publication
"Acceleration-as-a-µService: A Cloud-native Monte-Carlo Option Pricing Engine on CPUs, GPUs and Disaggregated FPGAs","Diamantopoulos, Dionysios, Polig, Raphael, Ringlein, Burkhard, Purandare, Mitra, Weiss, Beat, Hagleitner, Christoph, Lantz, Mark, Abel, Francois","<p>The evolution of cloud applications into loosely-coupled microservices opens new opportunities for hardware accelerators to improve&nbsp;workload performance. Existing accelerator techniques for cloud sacrifice the consolidation benefits of microservices. This&nbsp;paper presents CloudiFi, a framework to deploy and compare accelerators as a cloud service. We evaluate our framework in the&nbsp;context of a financial workload and present early results indicating up to 485x gains in microservice response time.</p>

<p>&nbsp;</p>",2023,"Cloud computing, Monte Carlo methods, Graphics processing units, Pricing, Hybrid Cloud, FPGA",10.1109/CLOUD53861.2021.00096,,publication
Security and risk analysis in the cloud with software defined networking architecture,"Nagaraju Thatha, Venkata, Donepudi, Swapna, Aruna Safali, Miriyala, Phani Praveen, Surapaneni, Trong Tung, Nguyen, Ha Huy Cuong, Nguyen","<p>Cloud computing has emerged as the actual trend in business information technology service models, since it provides processing that is both costeffective and scalable. Enterprise networks are adopting software-defined networking (SDN) for network management flexibility and lower operating costs. Information technology (IT) services for enterprises tend to use both technologies. Yet, the effects of cloud computing and software defined networking on business network security are unclear. This study addresses this crucial issue. In a business network that uses both technologies, we start by looking at security, namely distributed denial-of-service (DDoS) attack defensive methods. SDN technology may help organizations protect against DDoS assaults provided the defensive architecture is structured appropriately. To mitigate DDoS attacks, we offer a highly configurable network monitoring and flexible control framework. We present a dataset shift-resistant graphic model-based attack detection system for the new architecture. The simulation findings demonstrate that our architecture can efficiently meet the security concerns of the new network paradigm and that our attack detection system can report numerous threats using real-world network data.</p>",2023,"Cloud computing, Distributed denial of service attack, secCloud, Software defined network, Virtual network",10.11591/ijece.v13i5.pp5550-5559,,publication
Sentiment Analysis of Tweets on Telangana State Government Flagship Schemes,"K. Bhuvaneshwari, Dr. S. A Jyothi Rani, Dr. V. V. Haragopal","<p><strong>Abstract: </strong>Over the last decade, the usage of social media has evolved to a greater extent. Today, social media platforms like Twitter, facebook, snapchat are vastly used to incept the opinions of public about a particular entity. Social media has become a great source of text data. Text analytics plays a crucial role on social media data to give answers to a wide variety of questions about public feedback on many issues or topics. The primary objective of this work is to analyse the public opinion or sentiment in social media on Telangana state government welfare schemes. The purpose of sentiment analysis is to find opinions from tweets and extract sentiments from them and find their polarity, i.e., positive, neutral or negative. Here we are using twitter as it has gained much popularity and media attention. The first step is to extract the tweets on particular schemes through Twitter API and Python language followed by cleaning and pre- processing steps of the raw tweets. Then tfidf vectoriser was invoked for feature extraction and creation of bag of words and finally sentiment polarity scores were obtained by using VADER (Valence Aware Dictionary and sEntiment Reasoner), lexicon and rule-based sentiment analysis tool.</p>",2023,"Sentiment Analysis, Twitter, Vader, Lexicon, Government Schemes",10.35940/ijeat.A3794.1012122,,publication
E-LEARNING DEVELOPMENT EXPERIENCE IN EUROPE,"Shmatko, Sergey Gennadievich, Lovyannikov, Denis Gennadievich","<p><em>Goal. The subsection is part of the Erasmus + Jean Monnet project &quot;Digital Economy and Education: European Experience&quot;. Its purpose is to describe the experience of the development of e&ndash;learning, identify problems, consider the experience of Europe in terms of this issue and outline development trends. Structure / methodology / approach. The paper outlines the main problems of e-learning in Europe, as well as the experience of using mass open online courses, their advantages and development trends. A separate part of the subsection is devoted to the role of free software in education and provides the experience of the European Union. The final part examines continuing education in Europe, the degree of its influence on the level of education, as well as the state of the country&#39;s economy. Results. The results of the study can be used in the development of effective measures of state support for stimulating the market of additional educational programs and the development of systems for independent assessment of the level of education and recognition of qualifications according to existing competencies. This will lead to an increase in labor productivity. This study is a generalization of data on the use of mass open online courses in Europe, identification of problems in the development of this technology, description of new trends, as well as identification of the value of this technology.</em></p>",2023,"e-education, mobile technologies, MOOK, digitalization, LMS.",10.5281/zenodo.8079019,,publication
INFORMATION AND COMMUNICATION TECHNOLOGIES AND THEIR SIGNIFICANCE,Muhriddin Kuzratov,"<p>The article describes information technology, information communication channels, modern information and communication technologies (ICT), tools, their importance, classification and characteristics.</p>",2023,"ICT, cloud computing, software, hardware, economic operations (transactions), communication technologies, database, telephone, mobile technologies, multimedia technologies, electronic mail (e-mail), conference, teletext, web camera, Internet",10.5281/zenodo.7501091,,publication
Big Data Platforms and Tools for Data Analytics in the Data Science Engineering Curriculum,Yuri Demchenko,"<p>This paper presents experiences of development and teaching courses on Big Data Infrastructure Technologies for Data Analytics (BDIT4DA) as a part of the general Data Science curricula. The authors built the discussed course based on the EDISON Data Science Framework (EDSF), in particular, Data Science Body of Knowledge (DS-BoK) related to Data Science Engineering knowledge area group (KAG-DSENG). The paper provides overview of the cloud based platforms and tools for Big Data Analytics and stresses importance of including into curriculum the practical work with clouds for future graduates or specialists workplace adaptability. The paper discusses a relationship between the DSENG BoK and Big Data technologies and platforms, in particular Hadoop based applications and tools for data analytics that should be promoted through all course activities: lectures, practical activities and self-study.&nbsp;</p>",2023,"EDISON Data Science Framework (EDSF), Big Data Infrastructure Technologies, Data Science Body of Knowledge (DS-BoK), Data Science Engineering, Hadoop ecosystem, Cloud Computing",10.5281/zenodo.7538483,,publication
Automated Face Recognition based Attendance System using  RetinaFace and FaceNet,"Umesh Hengaju, Nabin Adhikari, Abhinav Aryal, Om Krishna Raut, Samundra Dahal","<p>Traditional approach for attendance in schools and colleges is professor calls the name or roll no. of students and record the attendance. The manual work included in the maintenance and management of the traditional attendance sheets is difficult and is a tedious work. This paper presents a system that automatically identifies and recognizes the individual in a live captured image and marks the attendance for that person. It is a web-based application in which RetinaFace algorithm has been used to detect the face in face image. FaceNet algorithm then extracts features from the image of a person&#39;s face and SVM classifier classifies the face based on extracted features. The classifier used here has been trained with 128 dimension values of each face. The developed system exhibits 99.76% accuracy on training data and 97.21% accuracy on validation data with Parameters of SVM as C=100, kernel=poly, degree=5 and probability=True. Other classifiers, namely, Random Forest, KNN and Logistic regression were also used for referencing with Accuracy, but among those, SVM classifier provided the best result.</p>",2023,"Face Detection, Face Recognition, RetinaFace, FaceNet, SVM, Random Forest,  KNN, Logistic regression, Accuracy",10.5281/zenodo.7524190,,publication
Bank Customer Churn Prediction,Jufin P A,"<p><strong>Abstract: </strong>In the current challenging era, there is a stiff competition happening between the banking industries. To strengthen the grade and level of services they provide, banks focus on customer retention as well as the customer churning. Customer churning becomes one of the duties of corporate intelligences to speculate the number of customers leaving from the bank or presumed to be churned. It also helps in predicting the number of customers retained. The primary objective of this paper is ""Bank customer churn prediction"" is to build a model that can distinguish and visualize which factors or attributes contribute to customer churn. In addition to that, this paper also discusses a comparison between various classification algorithms. Machine learning is a modern technology that has the potential to solve classification problems. Using supervised machine learning techniques, a best model is chosen that will assign a probability to the churn to simplify customer service to prevent customer churn. Few methodologies are compared in order to accomplish different accuracy levels. XGBoost is considered in order to check if a better model can be obtained that provides best result in terms of accuracy. The other three machine learning algorithms compared are Logistic regression, Support vector machine [SVM], and Random Forest.</p>",2023,"Customer Churning, Machine Learning, XG Boost, Logistic Regression, SVM, Random Forest",10.54105/ijdm.B1628.112222,,publication
Visualization of distance learning,Lyudmila Kondratova,"<p>The article is devoted to highlighting the current problems of creating visual support for distance learning of pedagogical workers in the conditions of postgraduate education. The current experience in training teachers to create a visualization of distance learning of teachers in postgraduate education is considered. Attention is paid to the modern problems of distance learning, the experience of organizing advanced training courses, implementation of thematic, author&#39;s courses for teachers of general secondary education institutions and vocational pre-higher education institutions is described. A description of the content of the training of teachers on the author&#39;s remote professional development courses is provided. A description of the preparation of a visual series for remote training of teachers in the postgraduate education system is given. Features of the use of modern digital tools and technology for creating electronic materials for the organization of distance learning are considered. A description of the use of video conferencing systems in distance learning is provided, examples of creating video materials for conducting distance classes are described. The experience of organizing distance classes is described and a description of the types of classes in distance learning is provided.</p>

<p>The list of problems of the pedagogical community in the process of organizing distance learning in crisis conditions is presented. The problems and needs of professional improvement of teachers, which can be solved during the period of professional development in the system of postgraduate education, are singled out.</p>

<p>The results of research in the post-graduate education system are described, which demonstrate the solution to the problems of distance learning visualization based on the author&#39;s professional development courses. The meaningful content of distance, network, electronic training of teachers, the selection of effective technologies for the preparation of visual support for conducting classes in a distance format are recognized</p>",2023,"distance learning, teaching staff, postgraduate education, visualization of distance learning, digital tools",10.15587/2519-4984.2023.275389,,publication
USE OF CLOUD TECHNOLOGIES IN THE EDUCATIONAL PROCESS,"Alieva Nodira, Djuraeva Saida, Abdusamatova Gulchekhra","<p>In maintaining the economic growth of a country, education plays an important role But in real life the practical knowledge, profound thinking, and some experience is required to remain in competition. In schools and even in the colleges,&nbsp; the&nbsp; traditional&nbsp; education&nbsp; system&nbsp; is&nbsp; applied&nbsp; which&nbsp; is&nbsp; proved&nbsp; useless&nbsp; many&nbsp; years&nbsp; ago.&nbsp; Nowadays the classroom teaching is changing and students are becoming more technology oriented and therefore in his changing environment, it&rsquo;s important that we think about the latest technologies to incorporate in the teaching and learning process. Because&nbsp; of&nbsp; the technology, it is possible to give the demonstration of the experiments, using presentation and the animation; it is now very easy to imagine the things. One of the latest technologies prevailing now days is Cloud Computing. By sharing IT services in the cloud, educational institution can outsource noncore services and better concentrate on offering students, teachers, faculty, and staff the essential tools to help them succeed. By using cloud computing. we can build the good education system and increase the quality of the system.</p>",2023,,10.5281/zenodo.7712615,,publication
ZEKRO: Zero-Knowledge Proof of Integrity Conformance,"Heini Bergsson Debes, Thanassis Giannetsos","<p>In the race towards next-generation systems of systems, the adoption of edge and cloud computing is escalating to deliver the un- derpinning end-to-end services. To safeguard the increasing attack landscape, remote attestation lets a verifier reason about the state of an untrusted remote prover. However, for most schemes, verifiability is only established under the omniscient and trusted verifier assumption where a verifier knows the prover&rsquo;s trusted states and the prover must reveal evidence about its current state. This assumption severely challenges upscaling, inherently limits eligible verifiers, and naturally prohibits adoption in public-facing security-critical networks. To meet current zero trust paradigms, we propose a general ZEro-Knowledge pRoof of cOnformance (ZEKRO) scheme, which considers mutually distrusting participants and enables a prover to convince an untrusted verifier about the correctness of its state in zero-knowledge by ensuring that the prover cannot cheat.</p>",2023,"Zero-Knowledge Configuration Integrity Verification, Configuration Privacy, Trusted Computing, Secure Zero-Touch Configuration",10.1145/3538969.3539004,,publication
IT Implementation Processes in Libraries: Adopting Foreign Experience,"Kulyk, Margaryta","<p><strong>Objective.</strong>&nbsp;The purpose of the article is to study the problems of implementing IT technologies in university libraries of Ukraine in the context of foreign experience. The article examines the retrospective of development of library information systems, their effectiveness and problematic issues related to the transition of library staff to work with them.&nbsp;<strong>Methods.&nbsp;</strong>When writing the article, the review, comparative, and historical methods were used to summarize the research on the development of library information systems and to choose a sufficiently effective and convenient system among ILS (Integrated Library System), LSP (Library Service Platform), LMS (Library Management System) or LIMS (Library Information Management System) for domestic university libraries.&nbsp;<strong>Results.</strong> The article provides a periodization of the development of library systems from 1931 till 2022. Problematic issues for Ukrainian university libraries related to the replacement of software tools with modern software products are identified. Specialists of higher education libraries are suggested to use the web-resource &ldquo;Library Technology Guides&rdquo; to select the latest innovative automated library systems with their subsequent configuration.&nbsp;<strong>Conclusions.</strong>&nbsp;As a result, the ILS Koha is proposed as more adapted system in terms of financial costs and possibility of its further maintenance by existing specialists.</p>",2023,"integrated library system (ILS), library service platform (LSP), library management system (LMS), library information management system (LIMS), cloud technologies, cloud computing",10.15802/unilib/2022_270925,,publication
Scalable and Extensible Cloud-Based Low-Code Model Repository,"Indamutsa, Arsene","<p>Low-code development platforms (LCDPs) are becoming increasingly common in the soft-<br>
ware industry. By leveraging visual diagrams, dynamic graphical user interfaces, and<br>
declarative languages, these platforms support the development of full-fledged applications<br>
in the cloud. However, given the rapid evolution of these platforms, they encounter a fleet of<br>
challenges and limitations. To address the challenges in Low-Code Development Platforms,<br>
it&rsquo;s essential to study their core concepts and technologies, primarily Model-Driven Engineer-<br>
ing (MDE) and cloud computing. Despite MDE&rsquo;s progress, its broader adoption is hindered<br>
by challenges faced by practitioners. The first obstacle is efficient support for discovering<br>
and reusing existing model artifacts. The development of similar tools and extensions leads<br>
to resource wastage, undermining productivity and collaboration in model-based processes.<br>
Additionally, local deployment of modeling environments causes scalability, extensibility,<br>
collaboration, and performance challenges. Consequently, modelers are required to engage<br>
in a process that involves downloading both artifacts and executables to their local ma-<br>
chines. This is a prerequisite step before initiating a potentially intricate and lengthy setup of<br>
Model-Driven Engineering (MDE) tools prior to their effective utilization.<br>
<br>
Throughout this dissertation, we attempted to advance state-of-the-art toward understanding<br>
and supporting cloud-based modeling in terms of LCDPs. Therefore, we aimed to enhance<br>
the scalability and extensibility of modeling infrastructures by developing a cloud-based<br>
low-code model repository. This approach goes beyond the typical implementation of<br>
repositories with simple storage and query capabilities. We provide a large-scale repository<br>
and services for low-code engineering (LCE). The implemented repository enables access,<br>
persistence, discovery, and reuse of modeling artifacts via scalable and extensible approaches<br>
and infrastructures. In the LCE context, core services are containerized, orchestrated, and<br>
deployed as cloud services. The repository&rsquo;s functionalities can be extended via its remote<br>
API or by adding functionality in the form of extensions and services. Finally, an integrated<br>
web-based search platform and various domain-specific languages are devised to support<br>
various mechanisms for composing, discovering, and reusing persisted artifacts and model<br>
management services.</p>",2023,"Model-Driven Engineering, Cloud-Based Low-Code Model Repository, Cloud Computing, Software Engineering, Domain-Specific Languages, Low-Code Engineering, Service Discovery, Scalability, Extensibility, Reusability",10.5281/zenodo.8193759,,publication
FAKE NEWS DETECTION AND CLASSIFICATION BASED ON LOGISTIC REGRESSION (LR) AND ARTIFICIAL NEURAL NETWORKS (ANN),Sourabh* & Rahul Kaushik**,"<p>Fake news detection has emerged as a crucial challenge in today&#39;s digital age, where misinformation can rapidly spread and influence public opinion. This paper addresses the problem of fake news detection by leveraging machine learning algorithms and natural language processing techniques. The objective is to develop a reliable and accurate model that can classify news articles as fake or genuine.The methodology involves data selection and loading, data preprocessing, splitting the dataset into train and test data, classification, prediction, and result generation. A labeled dataset comprising examples of both fake and genuine news articles is collected and preprocessed to remove noise and irrelevant information. The dataset is then split into training and testing subsets to train a classification model.Two classification algorithms, Logistic Regression (LR) and Artificial Neural Networks (ANN), are utilized to build the fake news detection model. LR provides a linear decision boundary, while ANN captures complex nonlinear relationships in the data. Both algorithms are trained on the preprocessed data, and their performances are evaluated using metrics such as accuracy, precision, recall, and F1 score.The results demonstrate that both LR and ANN achieve high accuracy in detecting fake news. LR offers interpretability, making it easier to understand the factors influencing the classification decisions. ANN exhibits better performance in capturing intricate patterns and relationships in the data.The findings of this study contribute to the development of effective fake news detection systems.</p>",2023,"Logistic Regression (LR) and Artificial Neural Networks (ANN), Fake News Detection, Social Media",10.5281/zenodo.8073505,,publication
A SYSTEMATIC REVIEW ON FAKE NEWS DETECTION USING MACHINE LEARNING APPROACHES,Sourabh,"<p>A Review of Methods and Approaches&quot; is a comprehensive review paper that explores the various methods and approaches employed in the detection of fake news. The paper provides an extensive overview of the existing literature, summarizing the key techniques and algorithms utilized in this field.The review highlights the importance of addressing the growing problem of fake news, particularly in the context of evolving communication channels and social media platforms. It emphasizes the need for effective detection mechanisms to combat the spread of misinformation and disinformation.The paper covers a wide range of approaches, including machine learning, natural language processing (NLP), deep learning, network analysis, and information retrieval. It delves into the advantages and limitations of each method, providing insights into their applicability and performance.Furthermore, the review addresses the challenges faced in this domain, such as limited datasets, lack of ground truth labels, and the dynamic nature of fake news. It also discusses the importance of feature engineering, dataset construction, and evaluation metrics for accurate and reliable detection.One notable aspect of the review is its focus on comparative evaluations of different approaches. It presents studies that benchmark various methods against each other, enabling readers to understand their relative strengths and weaknesses.</p>",2023,"Fake News Detection, Machine Learning Algorithms, Natural Language Processing, Social Media, Text Mining.",10.5281/zenodo.8073703,,publication
Securing the Cloud: Best Practices for a Resilient and Compliant Cloud Infrastructure,"Gagandeep, Harsh Kishore Mishra","<p>In today&#39;s digital landscape, the adoption of cloud computing is pivotal for organizations seeking agility and scalability. However, as cloud environments grow in complexity, ensuring security, resilience, and compliance becomes paramount. This white paper, &#39;Securing the Cloud: Best Practices for a Resilient and Compliant Cloud Infrastructure,&#39; delves into the ever-evolving realm of cloud security, offering practical insights and comprehensive best practices. Covering critical aspects such as access controls, encryption, identity management, monitoring, and incident response, it equips IT professionals with the knowledge needed to safeguard cloud assets effectively. Additionally, the paper explores navigating complex regulatory landscapes to maintain compliance with data protection laws. &#39;Securing the Cloud&#39; serves as an essential guide for businesses aiming to harness cloud advantages while protecting their digital infrastructure from emerging threats and ensuring regulatory adherence.</p>",2023,"IAAS, SAAS, PAAS, Cloud Security",10.5281/zenodo.8398694,,publication
FOSSR First General Conference: project presentations,"Zinilli, Antonio, Paolucci, Mario, Stefanizzi, Sonia, Ciampi, Mario, Sicuranza, Mario, CERULLI, GIOVANNI, Nuzzolese, Andrea Giovanni, Sprocati, Marco, Caporale, Cinzia, Saccone, Massimiliano, Spinello, Andrea Orazio, Stilo, Alessandra Maria","<p>The first yearly FOSSR General Conference intended to <strong>share with the diverse stakeholders and publics of the project the results and advancements of each package of research</strong>, as well as <strong>offer a discussion space for researchers to fine-tune the work plan</strong>, adapting to the development of the project.&nbsp; The folder contains all presentations following the list below:</p><p>&nbsp;</p><p><strong>Data Collection</strong> &nbsp;</p><p>""Automated data collection and Network Analysis: latest updates from FOSSR"", Antonio Zinilli &nbsp;</p><p>""Probabilistic panel for research"", Mario Paolucci &nbsp;</p><p>&nbsp;</p><p><strong>An open cloud for Social Studies &nbsp;</strong></p><p>""Giving value to research data: data curation in the FOSSR project"", Sonia Stefanizzi &nbsp;</p><p>""Open cloud: Network of Data Center and Cloud Computing Infrastructure"", Mario Ciampi, Mario Sicuranza &nbsp;</p><p>&nbsp;</p><p><strong>&nbsp;Data Analysis &nbsp;</strong></p><p>""Policy Learning Platform': state of the art and critical issues"", Giovanni Cerulli &nbsp;</p><p>""Ontologies, patterns and modelling solutions for enhancing data to knowledge graphs in FOSSR"", Andrea Giovanni Nuzzolese &nbsp;</p><p>&nbsp;</p><p><strong>Governance &nbsp;</strong></p><p>""The first steps of the Strategic Management Committee and the role of the FOSSR Stakeholder Advisory Board"", Marco Sprocati &nbsp;</p><p>&nbsp;""Ethics@FOSSR, preliminary remarks"", Cinzia Caporale &nbsp;</p><p>""The first steps of the Governing Board and the role of the Scientific Advisory Board, Massimiliano Saccone &nbsp;</p><p>&nbsp;</p><p><strong>Training and communication &nbsp;</strong></p><p>""Enhancing Skills, Building Communities: The FOSSR Training Initiatives"", Andrea Orazio Spinello &nbsp;</p><p>""Communication, Dissemination &amp; Outreach"", Alessandra M. Stilo&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",2023,"PNRR, FOSSR PROJECT, OPEN CLOUD, OPEN SCIENCE, OPEN DATA, SOCIAL SCIENCES, CESSDA, SHARE, RISIS",10.5281/zenodo.10046910,,presentation
Applications Integration in a Semi-Virtualized Environment,Bery Leouro,"<p><strong>Abstract: </strong>Enterprise application integration quickly arose as a problem for companies and solutions were proposed including point-to-point architecture, ETL (Extract, Transform and Load), EAI (Enterprise Application Integration) and ESBs (Enterprise Service Bus). With the rise of virtualization, how applications in a physical environment could interact with those that are in a virtualized environment. The objective of this paper is to study and define a Service Oriented Architecture (SOA) in a semi-virtualized environment. The authors propose an architecture which allows service integration in a semi-virtualized environment. This study uses a survey-based technique to seek which technology can be used in the considered environment. A state-of-the-art of the various IT designs and solutions enabling SOA implementation is presented. ESB technology has been retained for this study. A literary review is done on ESB to examine how it could be used in the semi-virtualized context. The findings of this study propose an architecture which allows service integration in a semi-virtualized environment. After an in-depth examination of different deployment possibilities and technical solutions proposed for this purpose, a new architecture based on the Enterprise Service Bus (ESB) is proposed for semi-virtualized context. This architecture is organized around two ESB solutions each deployed in an environment and interconnected by a communication bridge which ensures message routing between the two ESB buses. A practical deployment phase is carried out for illustration under Talend Open Studio with encouraging results. The proposed architecture is a good solution for companies whose information systems operate in a semi-virtualized environment.</p>",2023,"Application Integration, Eia, Esb, Soa, Virtualization, Semi-Virtualized Context.",10.35940/ijitee.B9403.0112223,,publication
Fuzzy System Approximation based Adaptive Sliding Mode Control for Nonlinear System,Dr. Monisha Pathak,"<p><strong>Abstract:</strong> In this paper, an adaptive sliding mode control utilizing a fuzzy system approximation is introduced. The fuzzy system is used to approximate the unknown function of an uncertain nonlinear system. The robustness of the system is ensured by the sliding mode control, while the adaptive fuzzy system improves real-time performance. To approximate unknown nonlinearities, a set of fuzzy rules is formulated whose parameters are adjusted in real-time by an adaptive algorithm. The chattering problem of sliding mode control is satisfactorily resolved, and stable operation is assured.</p>",2023,"Sliding Mode Control, Fuzzy Logic Control, Nonlinear system, Adaptive Control, Fuzzy System Approximation",10.35940/ijeat.B4338.1213223,,publication
An Application for Federated Learning of XAI Models in Edge Computing Environments,"Bechini, Alessio, Daole, Mattia, Ducange, Pietro, Marcelloni, Francesco, Renda, Alessandro","<p>The next generation of wireless networks will feature an increasing number of connected devices which will produce an unprecedented volume of data. Knowledge extraction from decentralized data imposes the exploitation of computing and learning paradigms that are able to tame the complexity of the network and meet the growing requirement of trustworthiness. In this regard, edge computing overcomes the limitations of cloud computing by moving virtualized computing and stor- age resources closer to data sources. Furthermore, Federated Learning has been recently proposed to allow multiple parties to collaboratively train an ML model without disclosure of private data. In this paper, we propose an application enabling Federated Learning of eXplainable AI models (Fed-XAI) in an edge computing environment. The proposal represents a step forward to the adoption of trustworthy AI in next generation wireless networks, ensuring both privacy preservation and ex- plainability. The application components are described, along with the workflow for the training and inference stages. Finally, we discuss the application deployment, in a simulated setting, for addressing a task of video streaming Quality of Experience forecasting in a vehicular network case study.</p>",2023,"Federated Learning, Explainable Artificial Intelligence, Edge Computing",10.1234/pending123456,,publication
METHODS AND ALGORITHMS OF PROTECTION AGAINST INFORMATION ATTACKS IN DIGITAL TRANSFORMATION,"Irgasheva, Durdona, Sodiqova, Dilnoza","<p><i>This systematic literature review explores the digital transformation (DT) and cybersecurity implications for achieving business resilience. DT involves transitioning organizational processes to IT solutions, which can result in significant changes across various aspects of an organization. However, emerging technologies such as artificial intelligence, big data and analytics, blockchain, and cloud computing drive digital transformation worldwide while increasing cybersecurity risks for businesses undergoing this process. This literature survey article highlights the importance of comprehensive knowledge of cybersecurity threats during DT implementation to prevent interruptions due to malicious activities or unauthorized access by attackers aiming at sensitive information alteration, destruction, or extortion from users. Cybersecurity is essential to DT as it protects digital assets from cyber threats. We conducted a systematic literature review using the PRISMA methodology in this research. Our literature review found that DT has increased efficiency and productivity but poses new challenges related to cybersecurity risks, such as data breaches and cyber-attacks. We conclude by discussing future vulnerabilities associated with DT implementation and provide recommendations on how organizations can mitigate these risks through effective cybersecurity measures. The paper recommends a staged cybersecurity readiness framework for business organizations to be prepared to pursue digital transformation.</i></p>",2023,,10.5281/zenodo.10226839,,publication
METHODS AND ALGORITHMS OF PROTECTION AGAINST INFORMATION ATTACKS IN DIGITAL TRANSFORMATION,"Irgashevav, Durdona, Sodiqova, Dilnoza","<p><i>This systematic literature review explores the digital transformation (DT) and cybersecurity implications for achieving business resilience. DT involves transitioning organizational processes to IT solutions, which can result in significant changes across various aspects of an organization. However, emerging technologies such as artificial intelligence, big data and analytics, blockchain, and cloud computing drive digital transformation worldwide while increasing cybersecurity risks for businesses undergoing this process. This literature survey article highlights the importance of comprehensive knowledge of cybersecurity threats during DT implementation to prevent interruptions due to malicious activities or unauthorized access by attackers aiming at sensitive information alteration, destruction, or extortion from users. Cybersecurity is essential to DT as it protects digital assets from cyber threats. We conducted a systematic literature review using the PRISMA methodology in this research. Our literature review found that DT has increased efficiency and productivity but poses new challenges related to cybersecurity risks, such as data breaches and cyber-attacks. We conclude by discussing future vulnerabilities associated with DT implementation and provide recommendations on how organizations can mitigate these risks through effective cybersecurity measures. The paper recommends a staged cybersecurity readiness framework for business organizations to be prepared to pursue digital transformation.</i></p>",2023,,10.5281/zenodo.10222954,,publication
EDISON Data Science Framework (EDSF): Addressing Demand for Data Science and Analytics Competences for the Data Driven Digital Economy,"Demchenko, Yuri, Cuadrado-Gallego, Juan J., Brewer, Steven, Wiktorski, Tomasz","<p>Emerging data driven economy including industry, research and business, requires new types of specialists that are capable to support all stages of the data lifecycle from data production and input to data processing and actionable results delivery, visualisation and reporting, which can be jointly defined as the Data Science professions family. Data Science is becoming a new recognised field of science that leverages the Data Analytics methods with the power of the Big Data technologies and Cloud Computing that both provide a basis for effective use of the data driven research and economy models. Data Science research and education require a multi-disciplinary approach and data driven/centric paradigm shift. Besides core professional competences and knowledge in Data Science, increasing digitalisation of Science and Industry also requires new type of workplace and professional skills that rise the importance of critical thinking, problem solving and creativity required to work in highly automated and dynamic environment. The education and training of the data related professions must reflect all multi-disciplinary knowledge and competences that are required from the Data Science and handling practitioners in modern, data driven research and the digital economy. In modern conditions with the fast technology change and strong skills demand, the Data Science education and training should be customizable and delivered in multiple forms, also providing sufficient lab facilities for practical training. This paper discusses aspects of building customizable and interoperable Data Science curricula for different types of learners and target application domains. The proposed approach is based on using the EDISON Data Science Framework (EDSF) initially developed in the EU funded Project EDISON and currently being maintained by the EDISON Community Initiative. &nbsp;</p>",2023,"Data Science, EDISON Data Science Framework (EDSF), Data Science Competences Framework, Data Science Model Curriculum, Data Science Body of Knowledge",10.5281/zenodo.7538380,,publication
Sequence Clock: A Dynamic Resource Orchestrator for Serverless Architectures,"Ioannis Fakinos, Achilleas Tzenetopoulos, Dimosthenis Masouros, Sotirios Xydis, Dimitrios Soudris","<p>Function-as-a-service (FaaS) represents the next frontier in the evolution of cloud computing being an emerging paradigm that removes the burden of configuration and management issues from users. This is achieved by replacing the well-established monolithic approach with graphs of standalone, small, stateless, event-driven components called functions. At the same time, from the cloud providers&rsquo; perspective, problems such as availability, load balancing and scalability need to be resolved without being aware of the functionality, behavior or resource requirements of their tenants&rsquo; code. However, in this context, functions&rsquo; containers coexist with others inside a host of finite resources, where a passive resource allocation technique does not guarantee a well-defined quality of service (QoS) in regards to time latency. In this paper, we present Sequence Clock, an expandable latency targeting tool that actively monitors serverless invocations in a cluster and offers execution of a sequential chain of functions, also known as pipelines or sequences, while achieving the targeted time latency. Two regulation methods were utilized, with one of them achieving up to 82% decrease in the severity of time violations and in some cases even eliminating them completely.</p>",2023,"serverless computing, FaaS, QoS, OpenWhisk, Kubernetes",10.5281/zenodo.7941063,,publication
Identifying Performance Anomalies in Fluctuating Cloud Environments: A Robust Correlative-GNN-based Explainable Approach,"Song, Yujia, Xin, Ruyue, Chen, Peng, Zhang, Rui, Chen, Juan, Zhao, Zhiming","<p>Cloud computing provides scalable and elastic resources to customers as a low-cost, on-demand utility service. Multivariate time</p>

<p>series anomaly detection is crucial to promise the overall performance of cloud computing systems. However, due to the complexity</p>

<p>and high dynamics of cloud environments, anomaly detections caused by irre gular fluctuations in data and the robustness of models</p>

<p>are a challenge. To address these issues, we propose a deep learning-based anomaly detection method for multivariate time series for</p>

<p>real-world operational clouds: Correlative-GNN with Multi-Head Self-Attention and Auto-Regression Ensemble Method (CGNNMHSA-</p>

<p>AR). Our method utilizes two parallel graph neural networks (GNN) to learn the time and feature inter-dependencies</p>

<p>to achieve fewer false positives. Our approach leverages a multi-head self-attention, GRU, and AR model to capture multipledimensional</p>

<p>information, leading to better detection robustness. CGNN-MHSA-AR can also provide an abnormal explanation</p>

<p>based on the prediction error of its constituent univariate series. We compare the detection performance of CGNN-MHSA-AR</p>

<p>with seven baseline methods on seven public datasets. The evaluation shows that the proposed CGNN-MHSA-AR outperforms</p>

<p>its competitors with an F1-Score of 0.871 on average and is 19.9% better than state-of-the-art baseline methods. In addition,</p>

<p>CGNN-MHSA-AR also offers to correctly identify the root cause of detected anomalies with up to 74.1% accuracy.</p>",2023,,10.1016/j.future.2023.03.020,,publication
A concept for application of integrated digital technologies to enhance future smart agricultural systems,"Gebresenbet, Girma, Bosona, Techane, Patterson, David, Persson, Henrik, Fischer, Benjamin, Mandaluniz, Nerea, Chirici, Gherardo, Zacepins, Aleksejs, Komasilovs, Vitalijs, Pitulac, Tudor, Nasirahmadi, Abozar","<p>Future agricultural systems should increase productivity and sustainability of food production and supply. For this, integrated and efficient capture, management, sharing, and use of agricultural and environmental data from multiple sources is essential. However, there are challenges to understand and efficiently use different types of agricultural and environmental data from multiple sources, which differ in format and time interval. In this regard, the role of emerging technologies is considered to be significant for integrated data gathering, analyses and efficient use. In this study, a concept was developed to facilitate the full integration of digital technologies to enhance future smart and sustainable agricultural systems. The concept has been developed based on the results of a literature review and diverse experiences and expertise which enabled the identification of stat-of-the-art smart technologies, challenges and knowledge gaps. The features of the proposed solution include: data collection methodologies using smart digital tools; platforms for data handling and sharing; application of Artificial Intelligent for data integration and analysis; edge and cloud computing; application of Blockchain, decision support system; and a governance and data security system. The study identified the potential positive implications i.e. the implementation of the concept could increase data value, farm productivity, effectiveness in monitoring of farm operations and decision making, and provide innovative farm business models. The concept could contribute to an overall increase in the competitiveness, sustainability, and resilience of the agricultural sector as well as digital transformation in agriculture and rural areas. This study also provided future research direction in relation to the proposed concept. The results will benefit researchers, practitioners, developers of smart tools, and policy makers supporting the transition to smarter and more sustainable agriculture systems. &copy; 2023 The Author(s)</p>",2023,,10.1016/j.atech.2023.100255,,publication
Continuous accounting implementation for a new future opening the black box through green transformational leadership by surveying Indonesia banking employees,"Dian Widiyati, Etty Murwaningsari, Juniati Gunawan","<p>This study intents to examine and analyze the continuous accounting implementation with green transformational leadership as moderation variable by conducting a survey. Accounting produce services that impacted by the industrial revolution, so that they need to prepare for the challenges of an industry that clings to inflexible rituals and indecision in adopting complex designs, technologies and processes. This study uses primary data through questionnaires survey. The sample was 614 employees of the finance and information technology division at banks registered with the Bank Based on Core Capital Group. The result present that digital capability has positive influence on continuous accounting implementation as well as green human capital and green transformational leadership. While, cybersecurity awareness has no influence on continuous accounting implementation. Green transformational leadership is strengthening influence cybersecurity awareness to continuous accounting implementation while the rest have no moderation effect. The implications of this study are theoretically the development of new measurements for digital capability. The practical implication is by increasing digital capability, companies can have special programs that focus on self-development in terms of technology. Accounting as one of the branches of science affected by technology needs to update the method of storing accounting data securely. The Indonesian Institute of Accountants can make regulations regarding continuous accounting. Finally, the implication for the banking is to be able to pay more attention to cybersecurity by creating specific cybersecurity programs</p>",2023,"continuous accounting, digitalization, cybersecurity, green concept, survey, banking, Indonesia",10.15587/1729-4061.2023.273567,,publication
TeraHeap: Reducing Memory Pressure in Managed Big Data Frameworks,"Kolokasis,  Iacovos G., Evdorou, Giannos, Akram, Shoaib, Kozanitis, Christos, Papagiannis, Anastasios, Zakkak, Foivos S., Pratikakis, Polyvios, Bilas, Angelos","<p>Big data analytics frameworks, such as Spark and Giraph, need to process and cache massive amounts of data that do not always fit on the managed heap. Therefore, frameworks temporarily move long-lived objects outside the managed heap (off-heap) on a fast storage device. However, this practice results in (1) high serialization/deserialization (S/D) cost and (2) high memory pressure when off-heap objects are moved back to the heap for processing.</p>

<p>In this paper, we propose TeraHeap, a system that eliminates S/D overhead and expensive GC scans for a large portion of the objects in big data frameworks. TeraHeap relies on three concepts. (1) It eliminates S/D cost by extending the managed runtime (JVM) to use a second high-capacity heap (H2) over a fast storage device. (2) It offers a simple hint-based interface, allowing big data analytics frameworks to leverage knowledge about objects to populate H2. (3) It reduces GC cost by fencing the garbage collector from scanning H2 objects while maintaining the illusion of a single managed heap.</p>

<p>We implement TeraHeap in OpenJDK and evaluate it with 15 widely used applications in two real-world big data frameworks, Spark and Giraph. Our evaluation shows that for the same DRAM size, TeraHeap improves performance by up to 73% and 28% compared to native Spark and Giraph, respectively. Also, it provides better performance by consuming up to 4.6&times; and 1.2&times; less DRAM capacity than native Spark and Giraph, respectively. Finally, it outperforms Panthera, a state-of-the-art garbage collector for hybrid memories, by up to 69%.</p>",2023,"Java Virtual Machine (JVM), large analytics datasets, serialization, large managed heaps, memory management, garbage collection, memory hierarchy, fast storage devices",10.1145/3582016.3582045,,publication
Proposta de implementação do método DMAIC na gestão logística voltado ao estoque: estudo de caso na Malbec Empreendimento LTDA,"Silva, Daniel Nunes, Silveira, Andreia Luiza Freitas da, Caldas, Jhonatha Moraes, Roberto, José Carlos Alves, Almeida, Victor da Silva","<p>Nos tempos atuais muitas empresas aderiram sistemas de gest&atilde;o integrados visando o aumento da produtividade, controle e efici&ecirc;ncia dentro da organiza&ccedil;&atilde;o, com isso, empresas que n&atilde;o adotam esses tipos de sistemas acabam ficando estagnadas com o decorrer do tempo, devido a suas plataformas de gest&atilde;o que acabam n&atilde;o atualizando seus sistemas de gest&atilde;o empresarial de acordo com o desenvolvimento das tecnologias atuais. O presente artigo tem como objetivo desenvolver um estudo de caso na empresa Malbec Empreendimento Imobili&aacute;rios LTDA, na cidade Manaus, estado do Amazonas, com foco no ramo de constru&ccedil;&atilde;o civil. Tendo isso em vista, a quest&atilde;o norteadora deste artigo &eacute;: como a implementa&ccedil;&atilde;o do m&eacute;todo DMAIC pode melhorar os processos de gest&atilde;o de estoque em uma empresa de constru&ccedil;&atilde;o civil? O objetivo geral deste estudo &eacute; implementar o m&eacute;todo DMAIC (Define, Measure, Analyze, Improve e Control) para melhoria nos processos de gest&atilde;o de estoque, efetuando melhorias no sistema integrado de gest&atilde;o empresarial (ERP) voltado ao setor de log&iacute;stica, na &aacute;rea de estocagem da organiza&ccedil;&atilde;o. A metodologia utilizada para o desenvolvimento deste artigo foi a utiliza&ccedil;&atilde;o de coleta de dados de forma quali-quantitativa, atrav&eacute;s de an&aacute;lise de documentos, revis&atilde;o bibliogr&aacute;fica e entrevistas in loco, que pode proporcionar dados e informa&ccedil;&otilde;es espec&iacute;ficas do centro problema, onde nortearam todo o desenvolvimento deste estudo. Este artigo tamb&eacute;m utilizar&aacute; a ferramenta da qualidade de 5W2H (What, Why, Where, When, Who, How e How Much) para auxiliar no desenvolvimento dos itens que foram elaborados a partir do m&eacute;todo DMAIC, alinhando duas metodologias organizacionais para chegar ao resultado esperado. Os principais resultados obtidos com este estudo s&atilde;o de estabelecer uma nova cadeia de processos em uma &aacute;rea organizacional da Malbec, elaborando e demonstrando a&ccedil;&otilde;es que visam intervir com o problema estabelecido. Conclui-se que o DMAIC como uma ferramenta de cria&ccedil;&atilde;o de planejamento de a&ccedil;&otilde;es, neste trabalho se demonstrou como a ferramenta ideal para identificar e certificar a&ccedil;&otilde;es para emprego de um sistema integrado de gest&atilde;o da empresa mais atualizado.</p>",2023,"Metodologia DMAIC, Gestão de Estoque, ERP",10.32749/nucleodoconhecimento.com.br/administracao/dmaic,,publication
NAVIGATING THE COSMOS - AN INNOVATIVE APPROACH WITH S=A⊕B FORMULA,"Brandl, Edenilson","<p>This article delves into the groundbreaking application of the S=A⊕B formula for calculating directions and paths in interstellar journeys, presenting an innovative and versatile approach to space navigation. Beginning with a thorough exploration of the formula's parameters, A and B, representing the spacecraft's position and dynamic acceptance criteria, respectively, the article discusses the adaptation of the formula to yield the resultant direction (S) for spacecraft optimization. It explores the incorporation of specific mathematical operations within B to handle diverse acceptance criteria, emphasizing the adaptability of the formula to changing interstellar conditions.</p><p>The article further examines the implementation of the S=A⊕B formula in computational simulations, allowing for the analysis of different scenarios and route optimization based on dynamic criteria. Acknowledging inherent limitations, such as sensitivity to acceptance criteria variations, the article highlights the importance of extensive simulations and tests to validate the formula's effectiveness under various interstellar conditions. The iterative process of refining the formula based on test results is emphasized, showcasing its continuous improvement for diverse situations encountered in interstellar travel.</p><p>Beyond space exploration, the article suggests potential applications of the S=A⊕B system in various fields, including finance, healthcare, and information theory. It concludes by outlining future directions for research, including the exploration of machine learning approaches and interdisciplinary collaborations, emphasizing the formula's role in advancing interstellar navigation and decision-making. This comprehensive exploration positions the S=A⊕B formula as a powerful tool with far-reaching implications across scientific and computational domains.</p><p>&nbsp;</p><p>Dieser Artikel befasst sich mit der bahnbrechenden Anwendung der S=A⊕B-Formel zur Berechnung von Richtungen und Pfaden bei interstellaren Reisen und stellt einen innovativen und vielseitigen Ansatz für die Weltraumnavigation vor. Der Artikel beginnt mit einer gründlichen Untersuchung der Parameter A und B der Formel, die die Position des Raumfahrzeugs bzw. die dynamischen Akzeptanzkriterien darstellen, und erörtert die Anpassung der Formel, um die resultierende Richtung (S) für die Optimierung des Raumfahrzeugs zu erhalten. Es untersucht die Einbeziehung spezifischer mathematischer Operationen in B zur Handhabung verschiedener Akzeptanzkriterien und betont die Anpassungsfähigkeit der Formel an sich ändernde interstellare Bedingungen.</p><p>Der Artikel untersucht außerdem die Implementierung der S=A⊕B-Formel in Computersimulationen, die die Analyse verschiedener Szenarien und die Routenoptimierung auf der Grundlage dynamischer Kriterien ermöglicht. Der Artikel erkennt inhärente Einschränkungen an, etwa die Empfindlichkeit gegenüber Variationen der Akzeptanzkriterien, und betont die Bedeutung umfangreicher Simulationen und Tests, um die Wirksamkeit der Formel unter verschiedenen interstellaren Bedingungen zu validieren. Der iterative Prozess der Verfeinerung der Formel auf der Grundlage von Testergebnissen wird hervorgehoben und zeigt ihre kontinuierliche Verbesserung für verschiedene Situationen, denen man bei interstellaren Reisen begegnet.</p><p>Über die Weltraumforschung hinaus schlägt der Artikel mögliche Anwendungen des S=A⊕B-Systems in verschiedenen Bereichen vor, darunter Finanzen, Gesundheitswesen und Informationstheorie. Abschließend werden zukünftige Forschungsrichtungen skizziert, einschließlich der Erforschung von Ansätzen des maschinellen Lernens und interdisziplinärer Zusammenarbeit, wobei die Rolle der Formel bei der Weiterentwicklung der interstellaren Navigation und Entscheidungsfindung hervorgehoben wird. Diese umfassende Untersuchung positioniert die S=A⊕B-Formel als leistungsstarkes Werkzeug mit weitreichenden Auswirkungen auf alle wissenschaftlichen und rechnerischen Bereiche.</p>",2023,"S=A⊕B Formula, interstellar navigation, space exploration, computational simulations, weighted summation formula, spacecraft optimization, dynamic acceptance criteria, mathematical operations, iterative refinement, limitations and validation",10.5281/zenodo.10156579,,publication
EXAMINING EMERGENT BEHAVIOR IN SUPPORT OF CYBER OPERATIONAL PREPARATION OF THE ENVIRONMENT,"Beard, David","<p>The primary goal of Cyber Operational Preparation of the Environment (C-OPE) is to enhance commanders' decision-making capability by providing detailed situational awareness of the operational environment. However, current cyberspace methodologies and technologies often fail to realize this goal due to the complex nature of cyberspace operations and the need for advanced, scalable military capabilities. This research seeks to improve commanders' situational awareness of the cyber operational environment by evaluating the efficacy of Monterey Phoenix (MP) in performing C-OPE activities. Specifically, this study performs emergent behavior analysis to examine MP's potential to enhance commanders' understanding, decision-making, and situational awareness. The research reconstructs the cybersecurity operations process as detailed in the Information Assurance and Computer Defense ""Autoimmunity Playbook for Information Brokers: Autoimmunity Analysis of Submitted Cyber Threat Information."" The research is presented through the lens of systems engineering, enabling the results to be contextualized within the cyber operational environment. The results of this study provide detailed examples and recommendations to USCYBERCOM's planners, analysts, and decision-makers on the use of MP as a tool for C-OPE activities and its potential to enhance situational awareness of the operational environment.</p>",2023,"model-based systems engineering, Monterey Phoenix, cyber, operations, NIST Cybersecurity Framework",10.5281/zenodo.10231772,,publication
Cyber Security in E-Commerce Sectors,Mr. Gunawan Widjaja,"<ol>
	<li>&nbsp;</li>
</ol>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The convenience and efficiency it offers have revolutionized the global economy, bringing products and services to our fingertips with just a few clicks. However, this convenience also brings forth a host of security challenges that cannot be ignored.</p>

<p>This book, &quot;Cyber Security in E-commerce,&quot; delves into the intricate realm where technology and commerce intersect, focusing on the critical aspects of security that underpin the functionality and reliability of online transactions. As the digital landscape evolves and businesses increasingly migrate to online platforms, the need to fortify these platforms against an array of cyber threats has never been more urgent.</p>

<p>The introductory chapter sets the stage by contextualizing e-commerce within the sphere of security concerns, emphasizing the need for systemic security practices and collaborative governance models. It sheds light on the potential risks that stem from the widespread adoption of electronic commerce, underlining the significance of robust security measures. Subsequent chapters delve into the underpinning technologies, ranging from e-commerce network technologies and blockchain to the emergent domains of virtual reality, cloud computing, and information security. These chapters equip readers with an understanding of the technological foundations necessary to secure the e-commerce landscape.</p>

<p>&nbsp;</p>

<p>The practical application of security principles takes center stage in another segment, elucidating the core tenets of confidentiality, integrity, and availability. The exploration spans the entire spectrum of e-commerce planning, development, and maintenance, ensuring that security remains paramount throughout. Moreover, the book navigates the intricate waters of combating Distributed Denial of Service (DDoS) attacks, detailing security solutions and testing methodologies.</p>

<p>&nbsp;</p>

<p>A pivotal chapter maps out the implementation of secure e-commerce websites, offering insights into security zones, firewalls, and intrusion detection systems. The importance of management and monitoring, whether in-house or outsourced, is examined in the context of maintaining a secure online presence. Real-world case studies, the cornerstone of this book, provide tangible examples of security breaches, thereby emphasizing the need for stringent security measures in e-commerce endeavors.</p>

<p>&nbsp;</p>

<p>In the ever-evolving world of e-commerce, security stands as the linchpin that safeguards transactions, privacy, and trust. &quot;Cyber Security in E-commerce&quot; is an indispensable resource that empowers readers to navigate the complex landscape of online business while bolstering their understanding of the strategies and technologies that can safeguard against cyber threats. As we embark on this enlightening journey, the book serves as a beacon of knowledge, guiding readers through the intricate web of cyber security in e-commerce and illuminating the pathways to a secure and prosperous digital commerce landscape.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Any unintentional errors, typos, omissions, or improvements to this work are much appreciated.</p>",2023,"Cyber Security , E-Commerce Sectors",10.5281/zenodo.8429484,,publication
A Review on Key Features and Novel Methods for Video Summarization,"Vinsent Paramanantham, Dr. S. Suresh Kumar","<p><strong>Abstract: </strong>In this paper, we discuss techniques, algorithms, evaluation methods used in online, offline, supervised, unsupervised, multi-video and clustering methods used for Video Summarization/Multi-view Video Summarization from various references. We have studied different techniques in the literature and described the features used for generating video summaries with evaluation methods, supervised, unsupervised, algorithms and the datasets used.We have covered the survey towards the new frontier of research in computational intelligence technique like ANN (Artificial Neural Network) and other evolutionary algorithms for VS using both supervised and unsupervised methods. We highlight on single, multi-video summarization with features like video, audio, and semantic embeddings considered for VS in the literature. A careful presentation is attempted to bring the performance comparison with Precision, Recall, F-Score, and manual methods to evaluate the VS.</p>",2023,"Video Summarization, Multi-View Video Summarization, Online Offline Video Highlighting, Key Frames, Sparse Coding, Feature Extraction, Sparse Land, CNN, RNN, LSTM.",10.35940/ijeat.F3737.0212323,,publication
ATHENS course DIGITAL SIGNAL AND IMAGE PROCESSING WITH APPLICATIONS 2023,"CURVO, Pedro, Le Blanc, Raphael, MACHADO, Maria Carolina, Sciarretta, Lorenzo, GEFFLAUT, Vincent, PIMENTA, Joana, WIŚNIEWSKI, Filip, EJARQUE BUENO, Lidia, NIEDZIAŁEK, Piotr, GAO, Shan, BIRRA, Pedro, FIGUEIREDO, Ivan Dos Santos, MOLČANOVÁ, Alexandra, SCHÄTZ, Martin, PROCHÁZKA, Aleš","<p>The ATHENS (Advanced Technology Higher Education Network, Socrates) week was established with the support of the European Communities SOCRATES Programme receiving an annual subsidy of 50&nbsp;000 Euros from 1997-2001. Today, the Programme is mainly founded by contributions from the member institutions.</p><p>The ATHENS Programme is aimed at carrying out intensive specialization courses, given at each member institution during one or two defined periods (""Sessions"") of the academic year (November and March), enabling students to attend one of the courses offered by the network universities during 7 days. This experience, in many cases, gives students the desire to carry out studies of a longer duration (MSc and PhD levels) at an institution different from their home institution and thus facilitates exchanges between students of the major European technological institutions.</p><p>&nbsp;</p><p>The ATHENS course <strong>DIGITAL SIGNAL AND IMAGE PROCESSING WITH APPLICATIONS</strong>, scheduled from November 20 to 24, 2023, offers an intensive program focused on signal processing and algorithmization within the MATLAB environment. The daily schedule is divided into three blocks - A, B, and C - with a variety of lectures, case studies, practical projects, and excursions. Here is a summary of the program:</p><p><strong>Monday (November 20, 2023):</strong></p><ul><li><strong>BLOCK A (9:00-12:00):</strong><ul><li>Lecture: Introduction to signal processing, MATLAB algorithmization, visualization, programming tools, structured arrays, data processing methods, linear algebra, least square method, approximation, and interpolation by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK B (13:00-14:30):</strong><ul><li>Lecture: Discrete Fourier transform, properties, frequency components detection, window functions, applications by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK C (14:30-16:00):</strong><ul><li>Case Study 1: DSP in neurology - Gait symmetry analysis by Bc. A. Molcanová.</li></ul></li></ul><p><strong>Tuesday (November 21, 2023):</strong></p><ul><li><strong>BLOCK A (9:00-12:00):</strong><ul><li>Lecture: Z-transform, difference equations, system description by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK B (13:00-14:30):</strong><ul><li>Lecture: DFT, short time Fourier transform, frequency transfer function by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK C (14:30-16:00):</strong><ul><li>Case Study 2: Sensors and data acquisition - Signal processing methods by Ing. M. Schatz, PhD.</li></ul></li></ul><p><strong>Wednesday (November 22, 2023):</strong></p><ul><li><strong>BLOCK A (9:00-12:00):</strong><ul><li>Lecture: Digital filtering using difference equations, FIR and IIR filters, frequency domain filtering by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK B (13:00-14:30):</strong><ul><li>Lecture: Discrete Wavelet transform, signal decomposition, de-noising, reconstruction by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK C (15:15 onwards):</strong><ul><li>Visit to the Technical Museum</li></ul></li></ul><p><strong>Thursday (November 23, 2023):</strong></p><ul><li><strong>BLOCK A (9:00-12:00):</strong><ul><li>Case Study 3: Deep learning in MATLAB environment - Computational intelligence in recognition problems by Ing. J. Jirkovský, PhD.</li></ul></li><li><strong>BLOCK B (13:00-14:30):</strong><ul><li>Excursion to Robotics and Machine Perception, Cloud Computing, and Intelligent Robots Departments, CTU CIIRC. Topics include computer vision, conversational AI, and mobile robots with contributions from Prof. V. Hlavác, PhD, Ing. J. Šedivý, CSc, and Ing. K. Košnar, PhD.</li></ul></li><li><strong>BLOCK C (14:30-16:00):</strong><ul><li>Projects: DSP in signal and image processing.</li></ul></li></ul><p><strong>Friday (November 24, 2023):</strong></p><ul><li><strong>BLOCK A (9:00-12:00):</strong><ul><li>DSP Applications: History and Interdisciplinary Applications of Computational Intelligence and Digital Signal and Image Processing by Prof. A. Procházka, CSc.</li></ul></li><li><strong>BLOCK B (Evaluation/12:00):</strong><ul><li>List of participants and final presentations, featuring the Scientific Board: Prof. A. Procházka, CSc, Ing. M. Yadollahi, PhD, RNDr. P. Cejnar, PhD, Ing. M. Schätz, PhD.</li></ul></li></ul><p>This comprehensive program covers a range of topics in signal processing, offering participants a mix of theoretical knowledge, practical skills, and exposure to real-world applications.</p>",2023,"digital signal processing, digital image processing, matlab, ATHENS",10.5281/zenodo.10203848,,event
Functionality Report: MCRA and low-end user apps,"van Klaveren, Jacob, Kolbaum, Anna, Peschko, Kerstin, Czach, Joanna","<p>Food may contain hazardous substances such as contaminants or residues from pesticides or food packaging materials. Food risk assessment requires different types of data e.g., chemical concentration, food consumption and health hazard data. Well-established datasets exist such as organized by the European Food Safety Authority (EFSA) and Member States data collection framework composed of national residue data and food consumption data collections, but so do emerging datasets, including data from total diet studies (TDS). TDS data can be very useful for food risk assessment because hazardous chemicals are measured in food as consumed. Data harmonization and data conversion are therefore essential steps in the assessment process. In addition, food risk assessment is complex and is constantly evolving, adopting different statistical approaches and ICT environments (e.g. cloud computing) as the discipline develops. Therefore, it is useful to develop demonstrator software to facilitate understanding and guide different user groups including risk assessors and low-end-users how to use e-services and the relevant data sets in international risk assessment or for training purposes.</p>

<p>The FNS-Cloud project created e-services that enable two types of user communities; low-end users (such as consumers or potential professional users that are not experts for TDS concept or exposure assessment) and researchers/risk assessors (experts and high-end users), to evaluate and visualize chemical food safety data after applying international risk assessment. Using the tools and services developed low-end users will be able to use concentration&nbsp;data from total diet studies (TDS) within the decision-making processes in their daily life, e.g., food purchasing and food choice. High-end users will be able to use TDS or monitoring data for higher-tier and more complex risk assessments analyses. Specifically, the latter approach will use the probabilistic assessment with the Monte Carlo Risk Assessment (MCRA) tool.</p>

<p>With the tools and services developed within FNS-Cloud there are five phases to this work split over WP 4 (Use cases) and WP 5 (Demonstrators), covering specification, implementation and testing (Task 4.3) and improvement and evaluation (in WP 5). For each use case, demonstrator software has been developed. In Part I of this report the functionalities of the MCRA TDS demonstrators and the MCRA Mixture Risk Assessment demonstrator are described &ndash; the high-end user tool. The demonstrators were tested by representatives of three groups namely 1) Academia, 2) public health institutes performing TDS (TDS centres) and 3) industry. Each group was initially trained to use the tools and e-services and after training the functionalities of the tools were discussed, and representatives of these groups also outlined their future user needs. Overall, they perceived the functionalities very positively, they understood the data formats and how their own private data could be used in the MCRA-software. Those in academia were able to familiarize themselves with new concepts in risk assessment using TDS data sets from three European Member States.</p>

<p>Finally the TDS network centres emphasized their needs to work in a harmonised approach. The first TDS demonstrator enabled them to organize their TDS data in internationally agreed formats such as the Standard Sample Description (SSD) format used by EFSA and the European Member States. Part II of this report describes the low-end user mobile app called FoodMagnifier. The aim of this app is to inform the general public about the content data of contaminants and residues in foods, based on the findings of Total Diet Studies. The app presents this information to the user in visual formats using graphs and charts, comparing the amount of substance in different types of foods. In addition to the content information, background information is also included, such as a description of the chemical, exposure statistics, health-based and toxicological reference values, and the role that different food categories play in dietary exposure. This deliverable also describes two usability tests that were performed with a wide variety of users, the results of those tests, as well as the improvements of the app based on those and the future plans.</p>",2023,"Monte Carlo Risk Assessment, Pesticides, Packaging materials, Total diet studies, Consumer tools",10.5281/zenodo.8262468,,publication
A proposed approach to enhance user PIN in the mobile money ecosystem in Ghana,"Kelly, Afful Ekow, Palaniappan, Sellappan","<p>The use of only numeric numbers as the base for the USSD PIN rather than alphanumeric was one of the security risks in the USSD mobile money services. The study objective is to assess the security threats posed by user PINs in the mobile money banking ecosystem and to enhance the service quality of the existing mobile money service with its high level of security threats prone to the mobile money industry. The study aims to shed light on the consumer acceptability requirements for mobile banking in particular areas of the consumer usage pattern, which will inform the industry players to strengthen such areas in consumer interest. This will help both the telecoms to understand the individuals and customise services based on the service needs of users of their product. This will aid the operators to cut costs and help improve the security infrastructure in other countries to cover to rope in more users, and to serve the unbanked in the hinterlands of the country. There is a growing demand for the adoption of mobile money services in Ghana. However, there is insufficient research to understand the risk associated with the adoption of the service. It is on this trend that, the study sought to reveal and understand the threat in the nature of user PIN used in the mobile money service. This study encapsulates, with the extension on demographic scope, which included workers, students, employed and unemployed who have adopted mobile money services the study adopted an exploratory method, to understand the main threats of the user PIN in relation to the mobile money application adopted in Ghana. This also included a survey question for users&rsquo; responses on the nature of use. The study included 57 participants to uncover the vulnerability of users&rsquo; PINs in mobile money services. The study&rsquo;s findings revealed that the length could be increased. The current size of the PIN stack was set to four for convenience and user-friendliness, with little thought given to the threat such a length could pose in financial transactions involving mobile money banking. The mobile money PIN solution provided will enable users not to be worried n about their accounts should users end up losing their handset and otherwise potentially harm their handsets because the merchandise is completely secure. The system is safeguarded by cutting-edge secure authentication, but also users&rsquo; funds are always secure because each transaction requires a secured alphanumeric password. The mobile payment process delivers individual clients with enhanced security but also lowers the need of carrying physical money but also ensures easy prompt payment of transactions of utilities. Individuals utilizing such services will manage to pay one&rsquo;s bill payments from the comfort of their place of arbour and making it even easier to do so. The use of only a numeric key for PIN was far more convenient for users, but it also made them more vulnerable to attacks. The standard PIN length in the current USSD mobile money application was four numeric keys. The indication was that the PIN length was too simple for a simple system to break through. The study proposed solution where mobile money users can increase their user PIN to six characters, and include alphanumeric keys. The study will help reduce the increasing threat of mobile money fraud in the FinTech industry.</p>",2023,"fraud, mobile money, mobile security, personal identification number, SMS threat, unstructured supplementary service data",10.47451/inn2022-11-01,,publication
Economic and cyber security,"Victor Krasnobayev, Alina Yanko, Alina Hlushko, Oleg Kruk, Oleksandr Kruk, Vitalii Gakh, Svitlana Onyshchenko, Oleksandra Maslii, Oleksandr Kivshyk, Kateryna Potapova, Mykola Nalyvaichuk, Vasyl Meliukh, Stanislav Gurynenko, Kostiantyn Koliada, Alexandre Scherbyna, Anastasiia Poltorak, Svitlana Tyshchenko, Olha Khrystenko, Volodimir Ribachuk, Vitalii Kuzoma, Viktoriia Stamat, Maksym Kolesnyk, Olena Arefieva, Dmytro Onopriienko, Yuliia Kovalenko, Tetiana Ostapenko, Iryna Hrashchenko","<p>Collective monograph highlights the results of systematic scientific research devoted to the problems of economic cyber security as a component of the financial security of the state, and contains practical recommendations on measures to strengthen the security of the state, in particular strategically important enterprises, in the presence of modern threats.</p>
<p>Chapter 1 analyzes the position of Ukraine in the global cyber security ratings and outlines promising directions for increasing its level, one of which is the improvement of information protection systems of critical infrastructure objects. A data comparison algorithm is considered, which consists in continuous monitoring and scanning of data by constantly comparing data with information patterns of users and services, as well as threat patterns and indicators based on previous experience, not only one's own, within a local network or system, but also globally scale An improved method of rapid data comparison is presented, which provides maximum accuracy of comparison with a minimum amount of equipment for comparing devices. Its use makes it possible to identify potential cyber threats and take preventive measures, which will increase the level of protection of critical infrastructure objects.</p>
<p>Chapter 2 focuses on defining strategic directions for ensuring economic cyber security of business in Ukraine. The importance of information protection in the context of the development of the digital economy has been updated, and the place of economic cyber security in the national security system has been determined. A thorough analysis of the dynamics of cyber incidents in the world in recent years was carried out and the specifics of the manifestation of cyber threats at the macro and micro levels were outlined. Special attention is paid to the intrusion detection process and a detailed study of the working principles of modern intrusion detection and prevention systems. It is expected that the use of the proposed recommendations on the cyber security policy will significantly increase the level of information security (confidentiality, integrity and availability) of the business.</p>
<p>Chapter 3 is dedicated to solving the problem of strengthening the security of strategically important enterprises of Ukraine by developing effective forms of implementation of the state regulatory policy in this direction. The issue of identifying strategically important enterprises and forming their security at the state level as a basis for supporting and restoring the national economy has been updated. The strategic directions of deregulation of business activity in Ukraine, including strategically important enterprises, have been determined. One of them is institutional support of state regulatory policy, improvement of regulatory policy. On the basis of the analysis of the existing institutional support of the state regulatory policy regarding strategically important enterprises, it has been proved that the basis of the formation of effective forms of implementation of the state regulatory policy of support and strengthening of the security of strategically important enterprises is the need to improve the current legislation, the formation of effective institutional and organizational support and the clustering of the national economy based on strategic important enterprises with the possibility of creating integrated corporate structures. A model of the process of assessing the effectiveness of the implementation of the state regulatory policy on ensuring the security of strategically important enterprises is proposed, which provides regulatory bodies with a tool to influence its level with the provision of economic development and social stability in Ukraine.</p>
<p>Chapter 4 explores Semantic role labeling (SRL) as a key Natural Language Processing (NLP) task that plays a vital role in extracting meaningful information from text. The role of SRL and its application is considered in the context of economics and cyber security, because the accurate definition and analysis of semantic roles in text is critical due to the rapid increase in the amount and complexity of textual information. State-of-the-art NLP classifiers used in decision-making, market analysis and financial reports, media articles, and economic texts are reviewed. It is emphasized that the process of determining relevant information from a large array of data collected from disparate sources requires an optimal methodological base, which should include the use of special tools for cleaning, tokenization, marking parts of speech with labels for preparation for NLP analysis. With the help of NLP classifiers, it becomes possible to automatically identify data, which allows to get information about market trends or security threats, depending on the specific field. It is noted that the proposed methods are practically significant, as they improve the ability to extract useful information, assess risks and make informed decisions by organizing unstructured textual data.</p>
<p>Chapter 5 is dedicated to the comprehensive substantiation of the theoretical and methodological foundations and practical methods of monitoring the state of financial security of Ukraine in conditions of economic turbulence as a factor ensuring the preservation of the state's financial system. Indicators of the state of financial security of regions are proposed and it is proved that they are not strongly connected, and also interconnected with the state of financial security of the state, which allows their use as input information in the process of calculating the integral indicator of the state of financial security of the region. On the basis of the proposed methodology for assessing the state of financial security of regions, integral indicators of the state of financial security of regions of Ukraine were calculated, which are actually the result of collapsing indicators by subsystems into a system index for a certain region, high values of which characterize a relatively stable value of financial security of a certain region, and low values signal its dangerous or critical condition.</p>
<p>Chapter 6 discusses the essence and features of the circular economy as an innovative com-ponent of the modern economy, which functions and develops on the basis of sustainable devel-opment, the deep reasons for its emergence, formation and transformation into a factor in the formation of a new paradigm of the global economy. Being a mechanism for the implementation of the Global Goals of sustainable development, the concept of a closed cycle economy encourages highly deve loped countries and businesses to introduce innovations and define the development of a circular economy as a priority in their long-term strategies.</p>
<p>The monograph is intended for researchers who are engaged in the development of measures to increase the financial security of the state, primarily through the development or improvement of security systems in cyberspace, as well as practitioners who are looking for the best scientific solutions for implementation, which can contribute to the formation of reliable cyber protection measures in the information environment of the enterprise, contributing to the increase of its financial security.</p>
<p>The monograph is also useful for state authorities, which are forced to search for operational, most effective solutions to ensure the financial security of the state as a whole, its strategic enterprises, including critical infrastructure, in particular through the regulation of security measures in the information space, in the presence of modern external threats.</p>",2023,"Integer economic data processing systems, modular number system, on-positional number system, economic cyber security, national economy, intrusion detection systems, nauthorized access, strategically important enterprises, state regulatory policy, institutional support, semantic role labeling, natural language processing, monitoring financial security, national security, circular economy",10.15587/978-617-7319-98-5,,publication
AGU 2023 Pre-Conference Workshop - Getting Started with NASA Earth Science Data: From Beginners to Experts (#193391),"Acker, James, Battisto, Christopher, Brennan, Jennifer, Joyner, Elizabeth R., KC, Binita, Lind, Bri","<h2>General Description</h2><p>Sunday, 10 December 2023: 08:00 - 15:00 PST&nbsp;</p><p>This workshop strives to demystify NASA Earth data, services, and tools for data users who are new to NASA data by showcasing commonly used data discovery, access, and application tools for researchers.&nbsp; The instruction and scaffolded/supported practice will offer 30 participants access to NASA subject matter experts (SME) who will provide strategies for finding and accessing freely open and available NASA Earth science data to help promote interdisciplinary research. Workshop facilitators span from across NASA's Earth Science Data Systems, Earth Science Data and Information System (ESDIS) Project, and Earth Observing System Data and Information System (EOSDIS). Together the SMEs will model strategies for accessing and downloading Earth observation data, including Earthdata in the cloud and facilitate learning with participants by providing dedicated time to access data and practice using popular tools and techniques. Tools such as Giovanni, Appears, Earthdata Search, and others will be featured. &nbsp;In an effort to better understand the needs of this user group a pre/post survey will be conducted. This will help to better meet the needs of the participants' with respect to skills, interests, datasets, and research domains.</p><p><i><strong>Please see </strong></i><strong>Requirements in the </strong><i><strong>Files </strong></i><strong>section for action items to address BEFORE Sunday's workshop. &nbsp;</strong>Review the general ""<a href=""https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.agu.org%2FFall-Meeting%2FPages%2FAttend%2FIn-Person%23kbyginperson&amp;data=05%7C01%7Celizabeth.r.joyner%40nasa.gov%7C1262f68e8aa047f0962908dbf662476d%7C7005d45845be48ae8140d43da96dd17b%7C0%7C0%7C638374674261173626%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=krR3%2FCCiRDR%2BOcfN0%2Ffnq9r2wpGvniBrvysgU%2FH%2FLBE%3D&amp;reserved=0"">Know Before your Go</a>"" reference guide for attendees for other important information.&nbsp;&nbsp;</p><h2>Location:</h2><p>Room: Moscone Center, 3005 - West</p><p>Moscone Center West Address:  &nbsp;</p><p>800 Howard St<br>(at the corner of Fourth &amp; Howard streets)<br>San Francisco, CA 94103&nbsp;</p><ul><li><a href=""https://www.agu.org/-/media/files/agu23/agu23-sf-walking-map.pdf"">Walking Map</a></li></ul><h3>Need help navigating? &nbsp;</h3><ul><li>San Francisco's <a href=""https://www.sftravel.com/info/meet-san-franciscos-welcome-ambassadors"">Welcome Ambassadors</a> are ready to help improve your visitors experience. Just look for their bright orange jackets!</li><li>San Francisco Community Ambassadors, retired San Francisco Police Officers, will be about and wearing blue and gray jackets</li><li>Yerba Buena Community Escorts – for assistance, please call 415-543-9223 / text: 415-559-1362 – they will walk you to/from a location in this area</li><li>Union Square Alliance Escorts – for assistance, please call: 415-781-4456 – they will walk you to/from a location in this area</li></ul><h3>Registration:</h3><p>On Sunday, all Learning Workshop organizers/presenters/attendees are required to enter the Moscone Center at the main entrance to the West Building. Registration for workshops <strong>will open at 7:30 AM </strong>on Sunday.  AGU requires all&nbsp;organizers/presenters/attendees&nbsp;attending AGU23 to visit the registration desk to collect their name badge and other conference materials.</p>",2023,"AGU, American Geophysical Union, Learning Workshop, NASA, Earthdata, Data, Tools, AppEEARS, Giovanni, Worldview, Earthdata Search, Earthdata Forum, Python, Google Colab, GESDISC, LP DAAC",10.5281/zenodo.10341740,,presentation
FROM THE ART OF SOFTWARE TESTING TO TEST-AS-A-SERVICE IN CLOUD COMPUTING,"Janete Amaral, Alberto S. Lima,, José Neuman de Souza, Lincoln S. Rocha","<p>Researchers consider that the first edition of the book &quot;The Art of Software Testing&quot; by Myers (1979) initiated research in Software Testing. Since then, software testing has gone through evolutions that have driven standards and tools. This evolution has accompanied the complexity and variety of software deployment platforms. The migration to the cloud allowed benefits such as scalability, agility, and better return on investment. Cloud computing requires more significant involvement in software testing to ensure that services work as expected. In addition to testing cloud applications, cloud computing has paved the way for testing in the Test-as-a-Service model. This review aims to understand software testing in the context of cloud computing. Based on the knowledge explained here, we sought to linearize the evolution of software testing, characterizing fundamental points and allowing us to compose a synthesis of the body of knowledge in software testing, expanded by the cloud computing paradigm.</p>",2023,Cloud Computing,10.5281/zenodo.7929320,,publication
Evolution and Development of Forensic Accounting,"A. O. Enofe, Henry K., Fasua","<p><strong><em>This study examines the evolution and development of forensic accounting. Since the study uses a library approach to look at the evolution and development forensic accounting, it is qualitative in nature. The analysis of the available literature revealed that forensic accounting combines knowledge and skills obtained from law, computer science, auditing and accounting to investigate issues reported (reactive) and predicted (proactive). We discovered that forensic accounting is a pragmatic profession.&nbsp; Therefore, it (forensic accounting) will be one of the brightest professions of the future with the cost of fraud and corruption to governments and the private sector and with the spread of industry 4.0 applications (artificial intelligence, big data, cloud computing and block chain). The future of forensic accounting will be shaped by technological advancements, specialization, regulatory compliance, interdisciplinary collaboration, and a focus on continuous professional development.</em></strong></p>",2023,"Forensic Accounting, Litigation Support, Expert Witnessing, Fraud Investigation",10.47760/cognizance.2023.v03i07.029,,publication
